<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Deep Learning Mastery Hub</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            color: #333;
            line-height: 1.6;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            padding: 20px;
        }

        .header {
            text-align: center;
            padding: 40px 0;
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            margin-bottom: 30px;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .header h1 {
            color: white;
            font-size: 3em;
            margin-bottom: 15px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }

        .header p {
            color: rgba(255, 255, 255, 0.9);
            font-size: 1.2em;
            max-width: 600px;
            margin: 0 auto;
        }

        .nav-tabs {
            display: flex;
            justify-content: center;
            flex-wrap: wrap;
            gap: 10px;
            margin-bottom: 30px;
        }

        .tab-btn {
            padding: 15px 25px;
            background: rgba(255, 255, 255, 0.1);
            color: white;
            border: none;
            border-radius: 10px;
            cursor: pointer;
            font-size: 1em;
            font-weight: 600;
            transition: all 0.3s ease;
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .tab-btn:hover {
            background: rgba(255, 255, 255, 0.2);
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(0,0,0,0.2);
        }

        .tab-btn.active {
            background: linear-gradient(135deg, #ff6b6b, #ee5a24);
            box-shadow: 0 8px 25px rgba(238, 90, 36, 0.3);
        }

        .content-section {
            display: none;
            background: white;
            border-radius: 20px;
            padding: 40px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.1);
            margin-bottom: 30px;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .content-section.active {
            display: block;
            animation: fadeIn 0.5s ease-in;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .section-title {
            color: #2c3e50;
            font-size: 2.5em;
            margin-bottom: 25px;
            text-align: center;
            position: relative;
        }

        .section-title::after {
            content: '';
            position: absolute;
            bottom: -10px;
            left: 50%;
            transform: translateX(-50%);
            width: 80px;
            height: 4px;
            background: linear-gradient(135deg, #ff6b6b, #ee5a24);
            border-radius: 2px;
        }

        .cards-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 25px;
            margin: 30px 0;
        }

        .card {
            background: linear-gradient(135deg, #f8f9fa, #e9ecef);
            padding: 25px;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
            transition: all 0.3s ease;
            border: 1px solid rgba(0,0,0,0.1);
        }

        .card:hover {
            transform: translateY(-5px);
            box-shadow: 0 20px 40px rgba(0,0,0,0.15);
        }

        .card h3 {
            color: #2c3e50;
            margin-bottom: 15px;
            font-size: 1.4em;
        }

        .code-block {
            background: #2d3748;
            color: #e2e8f0;
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            overflow-x: auto;
            border-left: 4px solid #4299e1;
        }

        .highlight {
            background: linear-gradient(135deg, #ffecd2, #fcb69f);
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
            border-left: 4px solid #ff6b6b;
        }

        .framework-comparison {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
            gap: 25px;
            margin: 30px 0;
        }

        .framework-card {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            padding: 30px;
            border-radius: 15px;
            text-align: center;
            transition: all 0.3s ease;
        }

        .framework-card:hover {
            transform: scale(1.05);
        }

        .framework-card h3 {
            font-size: 1.8em;
            margin-bottom: 20px;
        }

        .pros-cons {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin: 20px 0;
        }

        .pros, .cons {
            padding: 20px;
            border-radius: 10px;
        }

        .pros {
            background: rgba(72, 187, 120, 0.1);
            border-left: 4px solid #48bb78;
        }

        .cons {
            background: rgba(245, 101, 101, 0.1);
            border-left: 4px solid #f56565;
        }

        .interactive-demo {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            padding: 30px;
            border-radius: 15px;
            margin: 30px 0;
        }

        .demo-controls {
            display: flex;
            gap: 15px;
            margin: 20px 0;
            flex-wrap: wrap;
        }

        .demo-btn {
            padding: 10px 20px;
            background: rgba(255, 255, 255, 0.2);
            color: white;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .demo-btn:hover {
            background: rgba(255, 255, 255, 0.3);
        }

        .pipeline-visual {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 20px;
            margin: 30px 0;
            padding: 30px;
            background: linear-gradient(135deg, #f093fb, #f5576c);
            border-radius: 15px;
            color: white;
        }

        .pipeline-step {
            text-align: center;
            flex: 1;
            min-width: 150px;
            padding: 20px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 10px;
            backdrop-filter: blur(10px);
        }

        .pipeline-arrow {
            font-size: 2em;
            color: white;
        }

        .trending-models {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }

        .model-card {
            background: linear-gradient(135deg, #a8edea, #fed6e3);
            padding: 25px;
            border-radius: 15px;
            text-align: center;
            transition: all 0.3s ease;
        }

        .model-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 20px 40px rgba(0,0,0,0.15);
        }

        .progress-bar {
            width: 100%;
            height: 10px;
            background: #e2e8f0;
            border-radius: 5px;
            margin: 10px 0;
            overflow: hidden;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(135deg, #667eea, #764ba2);
            border-radius: 5px;
            transition: width 0.3s ease;
        }

        .quiz-container {
            background: linear-gradient(135deg, #ffecd2, #fcb69f);
            padding: 30px;
            border-radius: 15px;
            margin: 30px 0;
        }

        .quiz-question {
            font-size: 1.2em;
            font-weight: bold;
            margin-bottom: 20px;
            color: #2c3e50;
        }

        .quiz-options {
            display: grid;
            gap: 10px;
        }

        .quiz-option {
            padding: 15px;
            background: white;
            border: 2px solid transparent;
            border-radius: 10px;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .quiz-option:hover {
            border-color: #667eea;
            background: #f8f9fa;
        }

        .quiz-option.correct {
            background: #d4edda;
            border-color: #28a745;
        }

        .quiz-option.incorrect {
            background: #f8d7da;
            border-color: #dc3545;
        }

        .collapsible {
            background: #f8f9fa;
            padding: 15px 20px;
            border: none;
            width: 100%;
            text-align: left;
            cursor: pointer;
            font-size: 1.1em;
            font-weight: 600;
            border-radius: 10px;
            margin: 10px 0;
            transition: all 0.3s ease;
        }

        .collapsible:hover {
            background: #e9ecef;
        }

        .collapsible.active {
            background: #667eea;
            color: white;
        }

        .collapsible-content {
            display: none;
            padding: 20px;
            background: white;
            border-radius: 0 0 10px 10px;
            border: 1px solid #e9ecef;
            border-top: none;
        }

        .collapsible-content.active {
            display: block;
            animation: slideDown 0.3s ease;
        }

        @keyframes slideDown {
            from { opacity: 0; max-height: 0; }
            to { opacity: 1; max-height: 500px; }
        }

        @media (max-width: 768px) {
            .container {
                padding: 10px;
            }
            
            .header h1 {
                font-size: 2em;
            }
            
            .content-section {
                padding: 20px;
            }
            
            .pipeline-visual {
                flex-direction: column;
            }
            
            .pipeline-arrow {
                transform: rotate(90deg);
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>🧠 Deep Learning Mastery Hub</h1>
            <p>Your comprehensive guide to mastering deep learning - from fundamentals to cutting-edge 2025 trends</p>
        </div>
<div class="nav-tabs">
    <a href="index.html" class="tab-btn active" style="text-decoration:none;">🏠 Home</a>
    <button class="tab-btn" onclick="showSection('fundamentals')">🔬 Fundamentals</button>
    <button class="tab-btn" onclick="showSection('ml-vs-dl')">🤖 ML vs DL</button>
    <button class="tab-btn" onclick="showSection('dl-types')">🧬 DL Types</button>
    <button class="tab-btn" onclick="showSection('architectures')">🏗️ Architectures</button>
    <button class="tab-btn" onclick="showSection('cnn-basics')">🖼️ CNN Basics</button>
    <button class="tab-btn" onclick="showSection('parameters')">⚙️ Parameters</button>
    <button class="tab-btn" onclick="showSection('llm')">🤖 LLM</button>
    <button class="tab-btn" onclick="showSection('pipeline')">🔄 ML Pipeline</button>
    <button class="tab-btn" onclick="showSection('metrics')">📊 DL Metrics</button>
    <button class="tab-btn" onclick="showSection('models')">🚀 Popular Models</button>
    <button class="tab-btn" onclick="showSection('frameworks')">🛠️ Frameworks</button>
    <button class="tab-btn" onclick="showSection('trends')">📈 2025 Trends</button>
    <button class="tab-btn" onclick="showSection('practice')">💻 Hands-on</button>
    <button class="tab-btn" onclick="showSection('quiz')">🎯 Quiz</button>
</div>
     

        <!-- Fundamentals Section -->
        <div id="fundamentals" class="content-section active">
            <h2 class="section-title">Deep Learning Fundamentals</h2>
            
            <div class="highlight">
                <h3>🎯 What is Deep Learning?</h3>
                <p>Deep learning is a subset of machine learning that uses artificial neural networks with multiple layers (hence "deep") to model and understand complex patterns in data. It mimics the human brain's neural networks to learn from vast amounts of data without explicit programming.</p>
            </div>

            <div class="cards-grid">
                <div class="card">
                    <h3>🧠 Neural Networks</h3>
                    <p><strong>Input Layer:</strong> Receives raw data</p>
                    <p><strong>Hidden Layers:</strong> Process and transform data through weighted connections</p>
                    <p><strong>Output Layer:</strong> Produces final predictions or classifications</p>
                    <p><strong>Activation Functions:</strong> Determine neuron activation (ReLU, Sigmoid, Tanh)</p>
                </div>

                <div class="card">
                    <h3>🎯 Key Concepts</h3>
                    <p><strong>Backpropagation:</strong> Algorithm for training networks by adjusting weights</p>
                    <p><strong>Gradient Descent:</strong> Optimization method to minimize loss</p>
                    <p><strong>Epochs:</strong> Complete passes through training data</p>
                    <p><strong>Learning Rate:</strong> Controls how much weights change during training</p>
                </div>

                <div class="card">
                    <h3>📊 Types of Learning</h3>
                    <p><strong>Supervised:</strong> Learning with labeled examples (classification, regression)</p>
                    <p><strong>Unsupervised:</strong> Finding patterns in unlabeled data (clustering, dimensionality reduction)</p>
                    <p><strong>Reinforcement:</strong> Learning through reward/penalty feedback</p>
                </div>
            </div>

            <button class="collapsible">📖 Deep Dive: Mathematical Foundation</button>
            <div class="collapsible-content">
                <div class="code-block">
# Basic neuron computation
def neuron_output(inputs, weights, bias):
    weighted_sum = sum(x * w for x, w in zip(inputs, weights)) + bias
    return activation_function(weighted_sum)

# Common activation functions
def relu(x): return max(0, x)
def sigmoid(x): return 1 / (1 + math.exp(-x))
def tanh(x): return math.tanh(x)
                </div>
            </div>

            <button class="collapsible">🔬 Advanced Topics</button>
            <div class="collapsible-content">
                <p><strong>Regularization:</strong> Techniques like dropout and L1/L2 regularization prevent overfitting</p>
                <p><strong>Batch Normalization:</strong> Normalizes inputs to each layer for faster training</p>
                <p><strong>Transfer Learning:</strong> Using pre-trained models as starting points</p>
                <p><strong>Attention Mechanisms:</strong> Allow models to focus on relevant parts of input</p>
            </div>
        </div>

<!-- Deep Learning Model Types Section -->
<div id="dl-types" class="content-section">
    <h2 class="section-title">🧬 Deep Learning Model Types & Concepts</h2>

    <div class="cards-grid">

        <div class="card">
            <h3>🔹 Single Layer Perceptron</h3>
            <p>
                <b>Use:</b> Basic binary classification (linearly separable data).<br>
                <b>Problem:</b> Cannot solve non-linear tasks like XOR.<br>
                <b>Solution:</b> Use multilayer networks with nonlinear activation.
            </p>
            <pre class="code-block">
# Pseudocode
output = activation(np.dot(inputs, weights) + bias)
            </pre>
        </div>

        <div class="card">
            <h3>🔹 Fully Connected Feedforward NN</h3>
            <p>
                <b>Use:</b> Universal function approximator.<br>
                <b>Problem:</b> Overfitting, vanishing gradients with deep networks.<br>
                <b>Solution:</b> Use regularization (dropout, L2), batch norm, ReLU activations, skip connections.
            </p>
            <pre class="code-block">
# 3-layer feedforward (PyTorch)
model = nn.Sequential(
    nn.Linear(784, 128),
    nn.ReLU(),
    nn.Linear(128, 64),
    nn.ReLU(),
    nn.Linear(64, 10)
)
            </pre>
        </div>

        <div class="card">
            <h3>🔹 Recurrent Neural Network (RNN)</h3>
            <p>
                <b>Use:</b> Sequential/time series data (text, audio, stock).</b><br>
                <b>Problem:</b> Vanishing/exploding gradients for long sequences.<br>
                <b>Solution:</b> Use LSTM or GRU, gradient clipping, attention mechanisms.
            </p>
            <pre class="code-block">
# RNN cell output
h_t = tanh(Wx * x_t + Wh * h_{t-1} + b)
            </pre>
        </div>

        <div class="card">
            <h3>🔹 GAN (Generative Adversarial Network)</h3>
            <p>
                <b>Use:</b> Data generation (images, audio, text).<br>
                <b>Problem:</b> Unstable training (mode collapse, vanishing gradients).<br>
                <b>Solution:</b> Use Wasserstein GAN, improved loss functions, careful architecture/batch norm.
            </p>
            <pre class="code-block">
# GAN Structure
Generator: noise → fake data<br>
Discriminator: real/fake data → classification
            </pre>
        </div>

        <div class="card">
            <h3>🔹 Reinforcement Learning</h3>
            <p>
                <b>Use:</b> Agents learn by interacting with environment (game playing, robotics).<br>
                <b>Problem:</b> Slow learning, unstable convergence.<br>
                <b>Solution:</b> Use experience replay, target networks, reward shaping.
            </p>
            <pre class="code-block">
# Q-learning update
Q(s,a) ← Q(s,a) + α [r + γ * max_a' Q(s',a') - Q(s,a)]
            </pre>
        </div>
    </div>

    <div class="highlight" style="margin-top:2em;">
        <h3>📆 Key Training Concepts</h3>
        <ul>
            <li><b>Epoch:</b> One complete pass through the entire training dataset.</li>
            <li><b>Batch:</b> Subset of training data processed before updating weights.</li>
            <li><b>Mini-batch Gradient Descent:</b> Speeds up learning and generalizes better than single-sample updates.</li>
        </ul>
    </div>
    
    <div class="cards-grid">
        <div class="card">
            <h3>🚩 Common Issues & Solutions</h3>
            <ul style="padding-left:1em;">
                <li><b>Overfitting:</b> Use dropout, data augmentation, early stopping.</li>
                <li><b>Vanishing/Exploding Gradients:</b> Use ReLU, batch norm, LSTM/GRU, gradient clipping.</li>
                <li><b>Unstable GAN Training:</b> Use improved loss, architecture tweaks, regularization.</li>
                <li><b>Slow RL Convergence:</b> Experience replay, reward shaping, target networks.</li>
            </ul>
        </div>
        <div class="card">
            <h3>🧩 Single Layer Perceptron</h3>
           
            <img src="images/singlelayer.png" alt="Single Layer Perceptron" style="width:100%;max-width:460px;">

        </div>

                <div class="card">
            <h3>🧩 Multi-Layer Perceptron (MLP)</h3>
           
            <img src="images/mlp.png" alt="Single Layer Perceptron" style="width:100%;max-width:460px;">

        </div>

    </div>

</div>



<!-- Deep Learning Performance Analysis Metrics Section -->
<div id="metrics" class="content-section">
    <h2 class="section-title">📊 Deep Learning Performance Metrics</h2>

    <div class="highlight">
        <h3>🔍 Why Metrics Matter?</h3>
        <p>Performance metrics help you evaluate, compare, and improve deep learning models. They tell you how well your model is learning, where it’s failing, and what to optimize next.</p>
    </div>

    <div class="cards-grid">
        <div class="card">
            <h3>🎯 Accuracy</h3>
            <p>Proportion of correct predictions.<br>
               <b>Formula:</b> <code>(TP + TN) / (TP + TN + FP + FN)</code></p>
            <pre class="code-block">
# Accuracy (PyTorch Example)
accuracy = (outputs.argmax(dim=1) == labels).float().mean().item()
            </pre>
        </div>

        <div class="card">
            <h3>🚦 Precision & Recall</h3>
            <p>
                <b>Precision:</b> Out of all predicted positives, how many were actually positive?<br>
                <b>Recall:</b> Out of all actual positives, how many did the model catch?
            </p>
            <pre class="code-block">
# Precision & Recall (scikit-learn)
from sklearn.metrics import precision_score, recall_score
precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)
            </pre>
        </div>

        <div class="card">
            <h3>⚖️ F1-Score</h3>
            <p>
                Harmonic mean of precision and recall.<br>
                <b>Formula:</b> <code>2 * (precision * recall) / (precision + recall)</code>
            </p>
            <pre class="code-block">
# F1-Score (scikit-learn)
from sklearn.metrics import f1_score
f1 = f1_score(y_true, y_pred)
            </pre>
        </div>

        <div class="card">
            <h3>📉 Loss Functions</h3>
            <p>
                Quantifies error between predicted and true values.<br>
                <b>Common:</b> Cross Entropy (Classification), MSE (Regression)
            </p>
            <pre class="code-block">
# Cross Entropy Loss (PyTorch)
import torch.nn as nn
loss_fn = nn.CrossEntropyLoss()
loss = loss_fn(preds, labels)
            </pre>
        </div>
    </div>

    <div class="cards-grid">
        <div class="card">
            <h3>🔵 ROC & AUC</h3>
            <p>
                <b>ROC Curve:</b> Shows trade-off between True Positive Rate and False Positive Rate.<br>
                <b>AUC:</b> Area under the ROC curve (higher is better).
            </p>
            <pre class="code-block">
from sklearn.metrics import roc_auc_score
auc = roc_auc_score(y_true, y_prob)
            </pre>
        </div>

        <div class="card">
            <h3>📊 Confusion Matrix</h3>
            <p>
                Visualizes TP, FP, TN, FN to analyze errors.
            </p>
            <pre class="code-block">
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_true, y_pred)
            </pre>
        </div>

        <div class="card">
            <h3>⏱️ Speed & Resource Metrics</h3>
            <p>
                <b>Training Time:</b> Seconds/epochs<br>
                <b>Inference Time:</b> Prediction speed<br>
                <b>Parameters:</b> Model size, FLOPs
            </p>
            <pre class="code-block">
import time
start = time.time()
# ...train or infer...
print('Time:', time.time() - start)
            </pre>
        </div>

        <div class="card">
            <h3>📈 Custom Metrics</h3>
            <p>
                Define task-specific metrics (IoU for segmentation, BLEU for NLP, etc.)
            </p>
            <pre class="code-block">
# Example: Intersection over Union
def iou(pred, target):
    intersection = (pred & target).float().sum()
    union = (pred | target).float().sum()
    return intersection / union
            </pre>
        </div>
    </div>
</div>



        <!-- ML vs DL Section -->
        <div id="ml-vs-dl" class="content-section">
            <h2 class="section-title">🤖 Machine Learning vs Deep Learning</h2>
            
            <div class="highlight">
                <h3>🎯 Key Relationship</h3>
                <p>Deep Learning is a subset of Machine Learning, which is itself a subset of Artificial Intelligence. Think of it as nested circles: AI ⊃ ML ⊃ DL</p>
            </div>

            <div class="framework-comparison">
                <div class="framework-card">
                    <h3>🧮 Traditional Machine Learning</h3>
                    <p><strong>Approach:</strong> Manual feature engineering</p>
                    <p><strong>Data Requirements:</strong> Works well with smaller datasets</p>
                    <p><strong>Processing:</strong> Less computational power needed</p>
                </div>

                <div class="framework-card">
                    <h3>🧠 Deep Learning</h3>
                    <p><strong>Approach:</strong> Automatic feature extraction</p>
                    <p><strong>Data Requirements:</strong> Requires large datasets</p>
                    <p><strong>Processing:</strong> High computational power (GPUs)</p>
                </div>
            </div>

            <div class="cards-grid">
                <div class="card">
                    <h3>📊 Traditional ML Workflow</h3>
                    <div class="pipeline-visual" style="background: linear-gradient(135deg, #74b9ff, #0984e3);">
                        <div class="pipeline-step">
                            <h4>📥 Raw Data</h4>
                            <p>Images, text, numbers</p>
                        </div>
                        <div class="pipeline-arrow">→</div>
                        <div class="pipeline-step">
                            <h4>🔧 Feature Engineering</h4>
                            <p>Manual extraction of features</p>
                        </div>
                        <div class="pipeline-arrow">→</div>
                        <div class="pipeline-step">
                            <h4>🤖 Algorithm</h4>
                            <p>SVM, Random Forest, etc.</p>
                        </div>
                        <div class="pipeline-arrow">→</div>
                        <div class="pipeline-step">
                            <h4>📈 Output</h4>
                            <p>Predictions</p>
                        </div>
                    </div>
                </div>

                <div class="card">
                    <h3>🧠 Deep Learning Workflow</h3>
                    <div class="pipeline-visual" style="background: linear-gradient(135deg, #a29bfe, #6c5ce7);">
                        <div class="pipeline-step">
                            <h4>📥 Raw Data</h4>
                            <p>Images, text, numbers</p>
                        </div>
                        <div class="pipeline-arrow">→</div>
                        <div class="pipeline-step">
                            <h4>🧠 Neural Network</h4>
                            <p>Automatic feature learning</p>
                        </div>
                        <div class="pipeline-arrow">→</div>
                        <div class="pipeline-step">
                            <h4>📈 Output</h4>
                            <p>Predictions</p>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pros-cons">
                <div class="pros">
                    <h4>✅ When to Use Traditional ML</h4>
                    <ul>
                        <li><strong>Small datasets:</strong> Less than 10,000 samples</li>
                        <li><strong>Interpretability needed:</strong> Decision trees, linear models</li>
                        <li><strong>Limited computational resources</strong></li>
                        <li><strong>Structured/tabular data:</strong> CSV files, databases</li>
                        <li><strong>Quick prototypes:</strong> Faster to implement and test</li>
                    </ul>
                </div>
                <div class="cons">
                    <h4>🚀 When to Use Deep Learning</h4>
                    <ul>
                        <li><strong>Large datasets:</strong> 100,000+ samples</li>
                        <li><strong>Complex patterns:</strong> Images, audio, text</li>
                        <li><strong>Unstructured data:</strong> Photos, videos, natural language</li>
                        <li><strong>High accuracy needed:</strong> State-of-the-art performance</li>
                        <li><strong>Automatic feature discovery</strong></li>
                    </ul>
                </div>
            </div>

            <button class="collapsible">📋 Detailed Comparison Table</button>
            <div class="collapsible-content">
                <table style="width: 100%; border-collapse: collapse; margin: 20px 0;">
                    <tr style="background: #f8f9fa;">
                        <th style="border: 1px solid #ddd; padding: 12px; text-align: left;">Aspect</th>
                        <th style="border: 1px solid #ddd; padding: 12px; text-align: left;">Traditional ML</th>
                        <th style="border: 1px solid #ddd; padding: 12px; text-align: left;">Deep Learning</th>
                    </tr>
                    <tr>
                        <td style="border: 1px solid #ddd; padding: 12px;"><strong>Data Size</strong></td>
                        <td style="border: 1px solid #ddd; padding: 12px;">Small to medium (100s to 10,000s)</td>
                        <td style="border: 1px solid #ddd; padding: 12px;">Large (10,000s to millions)</td>
                    </tr>
                    <tr style="background: #f8f9fa;">
                        <td style="border: 1px solid #ddd; padding: 12px;"><strong>Feature Engineering</strong></td>
                        <td style="border: 1px solid #ddd; padding: 12px;">Manual, domain expertise required</td>
                        <td style="border: 1px solid #ddd; padding: 12px;">Automatic, learned from data</td>
                    </tr>
                    <tr>
                        <td style="border: 1px solid #ddd; padding: 12px;"><strong>Interpretability</strong></td>
                        <td style="border: 1px solid #ddd; padding: 12px;">High (can explain decisions)</td>
                        <td style="border: 1px solid #ddd; padding: 12px;">Low (black box)</td>
                    </tr>
                    <tr style="background: #f8f9fa;">
                        <td style="border: 1px solid #ddd; padding: 12px;"><strong>Training Time</strong></td>
                        <td style="border: 1px solid #ddd; padding: 12px;">Minutes to hours</td>
                        <td style="border: 1px solid #ddd; padding: 12px;">Hours to days/weeks</td>
                    </tr>
                    <tr>
                        <td style="border: 1px solid #ddd; padding: 12px;"><strong>Hardware Requirements</strong></td>
                        <td style="border: 1px solid #ddd; padding: 12px;">CPU sufficient</td>
                        <td style="border: 1px solid #ddd; padding: 12px;">GPU/TPU preferred</td>
                    </tr>
                    <tr style="background: #f8f9fa;">
                        <td style="border: 1px solid #ddd; padding: 12px;"><strong>Performance on Complex Data</strong></td>
                        <td style="border: 1px solid #ddd; padding: 12px;">Limited</td>
                        <td style="border: 1px solid #ddd; padding: 12px;">Excellent</td>
                    </tr>
                </table>
            </div>

            <div class="code-block">
# Example: Same problem, different approaches

# Traditional ML approach
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer

# Manual feature extraction
vectorizer = TfidfVectorizer(max_features=1000)
X_tfidf = vectorizer.fit_transform(text_data)

# Traditional classifier
rf_model = RandomForestClassifier(n_estimators=100)
rf_model.fit(X_tfidf, y_labels)

# Deep Learning approach
import tensorflow as tf

# Automatic feature learning
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(num_classes, activation='softmax')
])

# End-to-end training
model.compile(optimizer='adam', loss='categorical_crossentropy')
model.fit(text_sequences, y_labels, epochs=50)
            </div>
        </div>

        <!-- Neural Network Architectures Section -->
        <div id="architectures" class="content-section">
            <h2 class="section-title">🏗️ Neural Network Architectures</h2>
            
            <div class="highlight">
                <h3>🎯 Understanding Network Architectures</h3>
                <p>Let's visualize how different neural network architectures are structured and how information flows through them.</p>
            </div>

            <!-- Single Layer Perceptron -->
            <div class="card">
                <h3>🔵 Single Layer Perceptron</h3>
                <p>The simplest neural network with only input and output layers (no hidden layers).</p>
                
                <div style="display: flex; justify-content: center; margin: 30px 0;">
                    <svg width="600" height="300" viewBox="0 0 600 300">
                        <!-- Input Layer -->
                        <g id="input-layer">
                            <text x="50" y="20" font-family="Arial" font-size="14" font-weight="bold" fill="#333">Input Layer</text>
                            <circle cx="80" cy="80" r="20" fill="#74b9ff" stroke="#0984e3" stroke-width="2"/>
                            <text x="75" y="85" font-family="Arial" font-size="12" fill="white">x₁</text>
                            
                            <circle cx="80" cy="140" r="20" fill="#74b9ff" stroke="#0984e3" stroke-width="2"/>
                            <text x="75" y="145" font-family="Arial" font-size="12" fill="white">x₂</text>
                            
                            <circle cx="80" cy="200" r="20" fill="#74b9ff" stroke="#0984e3" stroke-width="2"/>
                            <text x="75" y="205" font-family="Arial" font-size="12" fill="white">x₃</text>
                        </g>
                        
                        <!-- Output Layer -->
                        <g id="output-layer">
                            <text x="450" y="20" font-family="Arial" font-size="14" font-weight="bold" fill="#333">Output Layer</text>
                            <circle cx="480" cy="140" r="25" fill="#fd79a8" stroke="#e84393" stroke-width="2"/>
                            <text x="475" y="145" font-family="Arial" font-size="12" fill="white">y</text>
                        </g>
                        
                        <!-- Connections -->
                        <line x1="100" y1="80" x2="455" y2="140" stroke="#636e72" stroke-width="2"/>
                        <line x1="100" y1="140" x2="455" y2="140" stroke="#636e72" stroke-width="3"/>
                        <line x1="100" y1="200" x2="455" y2="140" stroke="#636e72" stroke-width="2"/>
                        
                        <!-- Weights -->
                        <text x="200" y="100" font-family="Arial" font-size="11" fill="#636e72">w₁</text>
                        <text x="250" y="140" font-family="Arial" font-size="11" fill="#636e72">w₂</text>
                        <text x="200" y="180" font-family="Arial" font-size="11" fill="#636e72">w₃</text>
                        
                        <!-- Formula -->
                        <text x="200" y="270" font-family="Arial" font-size="14" fill="#333">y = f(w₁x₁ + w₂x₂ + w₃x₃ + b)</text>
                    </svg>
                </div>
                
                <div class="code-block">
# Single Layer Perceptron Implementation
import numpy as np

class Perceptron:
    def __init__(self, input_size, learning_rate=0.01):
        self.weights = np.random.normal(0, 0.1, input_size)
        self.bias = 0
        self.learning_rate = learning_rate
    
    def activation(self, x):
        return 1 if x >= 0 else 0  # Step function
    
    def predict(self, inputs):
        summation = np.dot(inputs, self.weights) + self.bias
        return self.activation(summation)
    
    def train(self, training_inputs, labels, epochs):
        for epoch in range(epochs):
            for inputs, label in zip(training_inputs, labels):
                prediction = self.predict(inputs)
                error = label - prediction
                
                # Update weights and bias
                self.weights += self.learning_rate * error * inputs
                self.bias += self.learning_rate * error

# Example usage
perceptron = Perceptron(input_size=2)
X_train = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y_train = np.array([0, 0, 0, 1])  # AND gate

perceptron.train(X_train, y_train, epochs=100)
                </div>
            </div>

            <!-- Multi-layer Feedforward Network -->
            <div class="card">
                <h3>🧠 Multi-layer Feedforward Network</h3>
                <p>Deep neural network with one or more hidden layers for learning complex patterns.</p>
                
                <div style="display: flex; justify-content: center; margin: 30px 0;">
                    <svg width="700" height="350" viewBox="0 0 700 350">
                        <!-- Input Layer -->
                        <g id="input-layer">
                            <text x="50" y="20" font-family="Arial" font-size="14" font-weight="bold" fill="#333">Input Layer</text>
                            <circle cx="80" cy="60" r="18" fill="#74b9ff" stroke="#0984e3" stroke-width="2"/>
                            <text x="75" y="65" font-family="Arial" font-size="11" fill="white">x₁</text>
                            
                            <circle cx="80" cy="110" r="18" fill="#74b9ff" stroke="#0984e3" stroke-width="2"/>
                            <text x="75" y="115" font-family="Arial" font-size="11" fill="white">x₂</text>
                            
                            <circle cx="80" cy="160" r="18" fill="#74b9ff" stroke="#0984e3" stroke-width="2"/>
                            <text x="75" y="165" font-family="Arial" font-size="11" fill="white">x₃</text>
                            
                            <circle cx="80" cy="210" r="18" fill="#74b9ff" stroke="#0984e3" stroke-width="2"/>
                            <text x="75" y="215" font-family="Arial" font-size="11" fill="white">x₄</text>
                        </g>
                        
                        <!-- Hidden Layer 1 -->
                        <g id="hidden-layer-1">
                            <text x="220" y="20" font-family="Arial" font-size="14" font-weight="bold" fill="#333">Hidden Layer 1</text>
                            <circle cx="250" cy="60" r="18" fill="#00b894" stroke="#00a085" stroke-width="2"/>
                            <text x="245" y="65" font-family="Arial" font-size="11" fill="white">h₁</text>
                            
                            <circle cx="250" cy="110" r="18" fill="#00b894" stroke="#00a085" stroke-width="2"/>
                            <text x="245" y="115" font-family="Arial" font-size="11" fill="white">h₂</text>
                            
                            <circle cx="250" cy="160" r="18" fill="#00b894" stroke="#00a085" stroke-width="2"/>
                            <text x="245" y="165" font-family="Arial" font-size="11" fill="white">h₃</text>
                            
                            <circle cx="250" cy="210" r="18" fill="#00b894" stroke="#00a085" stroke-width="2"/>
                            <text x="245" y="215" font-family="Arial" font-size="11" fill="white">h₄</text>
                            
                            <circle cx="250" cy="260" r="18" fill="#00b894" stroke="#00a085" stroke-width="2"/>
                            <text x="245" y="265" font-family="Arial" font-size="11" fill="white">h₅</text>
                        </g>
                        
                        <!-- Hidden Layer 2 -->
                        <g id="hidden-layer-2">
                            <text x="390" y="20" font-family="Arial" font-size="14" font-weight="bold" fill="#333">Hidden Layer 2</text>
                            <circle cx="420" cy="85" r="18" fill="#fdcb6e" stroke="#f39c12" stroke-width="2"/>
                            <text x="415" y="90" font-family="Arial" font-size="11" fill="white">h₆</text>
                            
                            <circle cx="420" cy="135" r="18" fill="#fdcb6e" stroke="#f39c12" stroke-width="2"/>
                            <text x="415" y="140" font-family="Arial" font-size="11" fill="white">h₇</text>
                            
                            <circle cx="420" cy="185" r="18" fill="#fdcb6e" stroke="#f39c12" stroke-width="2"/>
                            <text x="415" y="190" font-family="Arial" font-size="11" fill="white">h₈</text>
                        </g>
                        
                        <!-- Output Layer -->
                        <g id="output-layer">
                            <text x="560" y="20" font-family="Arial" font-size="14" font-weight="bold" fill="#333">Output Layer</text>
                            <circle cx="590" cy="110" r="20" fill="#fd79a8" stroke="#e84393" stroke-width="2"/>
                            <text x="585" y="115" font-family="Arial" font-size="11" fill="white">y₁</text>
                            
                            <circle cx="590" cy="160" r="20" fill="#fd79a8" stroke="#e84393" stroke-width="2"/>
                            <text x="585" y="165" font-family="Arial" font-size="11" fill="white">y₂</text>
                        </g>
                        
                        <!-- Connections Input to Hidden 1 -->
                        <line x1="98" y1="60" x2="232" y2="60" stroke="#636e72" stroke-width="1" opacity="0.6"/>
                        <line x1="98" y1="60" x2="232" y2="110" stroke="#636e72" stroke-width="1" opacity="0.6"/>
                        <line x1="98" y1="60" x2="232" y2="160" stroke="#636e72" stroke-width="1" opacity="0.6"/>
                        <line x1="98" y1="110" x2="232" y2="60" stroke="#636e72" stroke-width="1" opacity="0.6"/>
                        <line x1="98" y1="110" x2="232" y2="110" stroke="#636e72" stroke-width="1" opacity="0.6"/>
                        <line x1="98" y1="160" x2="232" y2="160" stroke="#636e72" stroke-width="1" opacity="0.6"/>
                        <line x1="98" y1="210" x2="232" y2="210" stroke="#636e72" stroke-width="1" opacity="0.6"/>
                        
                        <!-- Connections Hidden 1 to Hidden 2 -->
                        <line x1="268" y1="60" x2="402" y2="85" stroke="#636e72" stroke-width="1" opacity="0.6"/>
                        <line x1="268" y1="110" x2="402" y2="135" stroke="#636e72" stroke-width="1" opacity="0.6"/>
                        <line x1="268" y1="160" x2="402" y2="185" stroke="#636e72" stroke-width="1" opacity="0.6"/>
                        
                        <!-- Connections Hidden 2 to Output -->
                        <line x1="438" y1="85" x2="570" y2="110" stroke="#636e72" stroke-width="1" opacity="0.6"/>
                        <line x1="438" y1="135" x2="570" y2="160" stroke="#636e72" stroke-width="1" opacity="0.6"/>
                        <line x1="438" y1="185" x2="570" y2="160" stroke="#636e72" stroke-width="1" opacity="0.6"/>
                        
                        <!-- Activation Functions -->
                        <text x="150" y="320" font-family="Arial" font-size="12" fill="#333">f₁(x) = ReLU</text>
                        <text x="300" y="320" font-family="Arial" font-size="12" fill="#333">f₂(x) = ReLU</text>
                        <text x="500" y="320" font-family="Arial" font-size="12" fill="#333">f₃(x) = Softmax</text>
                    </svg>
                </div>
                
                <div class="code-block">
# Multi-layer Feedforward Network Implementation
import torch
import torch.nn as nn
import torch.nn.functional as F

class MultilayerPerceptron(nn.Module):
    def __init__(self, input_size, hidden_sizes, output_size, dropout_rate=0.3):
        super(MultilayerPerceptron, self).__init__()
        
        # Create layers dynamically
        layers = []
        prev_size = input_size
        
        # Hidden layers
        for hidden_size in hidden_sizes:
            layers.append(nn.Linear(prev_size, hidden_size))
            layers.append(nn.ReLU())
            layers.append(nn.Dropout(dropout_rate))
            prev_size = hidden_size
        
        # Output layer
        layers.append(nn.Linear(prev_size, output_size))
        
        self.network = nn.Sequential(*layers)
    
    def forward(self, x):
        return self.network(x)

# Example usage
model = MultilayerPerceptron(
    input_size=784,      # For MNIST (28x28 images)
    hidden_sizes=[256, 128, 64],  # Three hidden layers
    output_size=10,      # 10 classes for digits
    dropout_rate=0.3
)

# Training setup
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

print(f"Model has {sum(p.numel() for p in model.parameters())} parameters")
                </div>
            </div>

            <!-- CNN Architecture -->
            <div class="card">
                <h3>🖼️ Convolutional Neural Network (CNN)</h3>
                <p>Specialized architecture for processing grid-like data such as images.</p>
                
                <div style="display: flex; justify-content: center; margin: 30px 0; overflow-x: auto;">
                    <svg width="900" height="400" viewBox="0 0 900 400">
                        <!-- Input Image -->
                        <g id="input-image">
                            <text x="30" y="20" font-family="Arial" font-size="12" font-weight="bold" fill="#333">Input Image</text>
                            <rect x="30" y="30" width="60" height="60" fill="#74b9ff" stroke="#0984e3" stroke-width="2" opacity="0.8"/>
                            <text x="55" y="65" font-family="Arial" font-size="10" fill="white">32×32×3</text>
                        </g>
                        
                        <!-- Conv Layer 1 -->
                        <g id="conv1">
                            <text x="130" y="20" font-family="Arial" font-size="12" font-weight="bold" fill="#333">Conv2D</text>
                            <rect x="130" y="30" width="50" height="50" fill="#00b894" stroke="#00a085" stroke-width="2" opacity="0.8"/>
                            <text x="150" y="58" font-family="Arial" font-size="9" fill="white">30×30×32</text>
                            <text x="130" y="95" font-family="Arial" font-size="8" fill="#666">3×3, 32 filters</text>
                        </g>
                        
                        <!-- MaxPool 1 -->
                        <g id="pool1">
                            <text x="200" y="20" font-family="Arial" font-size="12" font-weight="bold" fill="#333">MaxPool</text>
                            <rect x="210" y="35" width="40" height="40" fill="#fdcb6e" stroke="#f39c12" stroke-width="2" opacity="0.8"/>
                            <text x="225" y="58" font-family="Arial" font-size="9" fill="white">15×15×32</text>
                            <text x="210" y="90" font-family="Arial" font-size="8" fill="#666">2×2</text>
                        </g>
                        
                        <!-- Conv Layer 2 -->
                        <g id="conv2">
                            <text x="280" y="20" font-family="Arial" font-size="12" font-weight="bold" fill="#333">Conv2D</text>
                            <rect x="280" y="35" width="35" height="35" fill="#00b894" stroke="#00a085" stroke-width="2" opacity="0.8"/>
                            <text x="293" y="56" font-family="Arial" font-size="8" fill="white">13×13×64</text>
                            <text x="280" y="85" font-family="Arial" font-size="8" fill="#666">3×3, 64 filters</text>
                        </g>
                        
                        <!-- MaxPool 2 -->
                        <g id="pool2">
                            <text x="340" y="20" font-family="Arial" font-size="12" font-weight="bold" fill="#333">MaxPool</text>
                            <rect x="350" y="40" width="25" height="25" fill="#fdcb6e" stroke="#f39c12" stroke-width="2" opacity="0.8"/>
                            <text x="360" y="56" font-family="Arial" font-size="8" fill="white">6×6×64</text>
                            <text x="350" y="80" font-family="Arial" font-size="8" fill="#666">2×2</text>
                        </g>
                        
                        <!-- Conv Layer 3 -->
                        <g id="conv3">
                            <text x="400" y="20" font-family="Arial" font-size="12" font-weight="bold" fill="#333">Conv2D</text>
                            <rect x="410" y="42" width="20" height="20" fill="#00b894" stroke="#00a085" stroke-width="2" opacity="0.8"/>
                            <text x="418" y="55" font-family="Arial" font-size="7" fill="white">4×4×128</text>
                            <text x="400" y="75" font-family="Arial" font-size="8" fill="#666">3×3, 128 filters</text>
                        </g>
                        
                        <!-- Flatten -->
                        <g id="flatten">
                            <text x="460" y="20" font-family="Arial" font-size="12" font-weight="bold" fill="#333">Flatten</text>
                            <rect x="470" y="30" width="8" height="60" fill="#a29bfe" stroke="#6c5ce7" stroke-width="2" opacity="0.8"/>
                            <text x="490" y="65" font-family="Arial" font-size="9" fill="#333">2048×1</text>
                        </g>
                        
                        <!-- Dense Layers -->
                        <g id="dense">
                            <text x="520" y="20" font-family="Arial" font-size="12" font-weight="bold" fill="#333">Dense Layers</text>
                            <circle cx="540" cy="45" r="8" fill="#fd79a8" stroke="#e84393" stroke-width="1"/>
                            <circle cx="540" cy="60" r="8" fill="#fd79a8" stroke="#e84393" stroke-width="1"/>
                            <circle cx="540" cy="75" r="8" fill="#fd79a8" stroke="#e84393" stroke-width="1"/>
                            <text x="520" y="100" font-family="Arial" font-size="8" fill="#666">512 neurons</text>
                            
                            <circle cx="580" cy="50" r="6" fill="#fd79a8" stroke="#e84393" stroke-width="1"/>
                            <circle cx="580" cy="65" r="6" fill="#fd79a8" stroke="#e84393" stroke-width="1"/>
                            <text x="570" y="85" font-family="Arial" font-size="8" fill="#666">128 neurons</text>
                        </g>
                        
                        <!-- Output -->
                        <g id="output">
                            <text x="620" y="20" font-family="Arial" font-size="12" font-weight="bold" fill="#333">Output</text>
                            <circle cx="640" cy="45" r="8" fill="#e17055" stroke="#d63031" stroke-width="2"/>
                            <circle cx="640" cy="60" r="8" fill="#e17055" stroke="#d63031" stroke-width="2"/>
                            <circle cx="640" cy="75" r="8" fill="#e17055" stroke="#d63031" stroke-width="2"/>
                            <text x="620" y="95" font-family="Arial" font-size="8" fill="#666">10 classes</text>
                        </g>
                        
                        <!-- Arrows -->
                        <line x1="95" y1="60" x2="125" y2="55" stroke="#636e72" stroke-width="2" marker-end="url(#arrowhead)"/>
                        <line x1="185" y1="55" x2="205" y2="55" stroke="#636e72" stroke-width="2" marker-end="url(#arrowhead)"/>
                        <line x1="255" y1="55" x2="275" y2="53" stroke="#636e72" stroke-width="2" marker-end="url(#arrowhead)"/>
                        <line x1="320" y1="53" x2="345" y2="53" stroke="#636e72" stroke-width="2" marker-end="url(#arrowhead)"/>
                        <line x1="380" y1="53" x2="405" y2="52" stroke="#636e72" stroke-width="2" marker-end="url(#arrowhead)"/>
                        <line x1="435" y1="52" x2="465" y2="60" stroke="#636e72" stroke-width="2" marker-end="url(#arrowhead)"/>
                        <line x1="485" y1="60" x2="515" y2="60" stroke="#636e72" stroke-width="2" marker-end="url(#arrowhead)"/>
                        <line x1="560" y1="60" x2="615" y2="60" stroke="#636e72" stroke-width="2" marker-end="url(#arrowhead)"/>
                        
                        <!-- Arrow marker definition -->
                        <defs>
                            <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="10" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#636e72"/>
                            </marker>
                        </defs>
                        
                        <!-- Process Description -->
                        <text x="50" y="150" font-family="Arial" font-size="14" font-weight="bold" fill="#333">Information Flow:</text>
                        <text x="50" y="175" font-family="Arial" font-size="12" fill="#666">1. Input image (32×32×3) → Raw pixel values</text>
                        <text x="50" y="195" font-family="Arial" font-size="12" fill="#666">2. Convolution → Feature detection (edges, textures)</text>
                        <text x="50" y="215" font-family="Arial" font-size="12" fill="#666">3. Pooling → Dimensionality reduction</text>
                        <text x="50" y="235" font-family="Arial" font-size="12" fill="#666">4. Multiple Conv+Pool → Complex feature hierarchy</text>
                        <text x="50" y="255" font-family="Arial" font-size="12" fill="#666">5. Flatten → Convert to 1D vector</text>
                        <text x="50" y="275" font-family="Arial" font-size="12" fill="#666">6. Dense layers → Classification decision</text>
                        <text x="50" y="295" font-family="Arial" font-size="12" fill="#666">7. Output → Probability distribution over classes</text>
                    </svg>
                </div>
                
                <div class="code-block">
# Complete CNN Architecture Implementation
import torch
import torch.nn as nn

class CNNClassifier(nn.Module):
    def __init__(self, num_classes=10):
        super(CNNClassifier, self).__init__()
        
        # Convolutional layers
        self.conv_layers = nn.Sequential(
            # First conv block
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            # Second conv block
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            # Third conv block
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        
        # Classifier layers
        self.classifier = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(128 * 4 * 4, 512),  # 4x4 assuming 32x32 input
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(512, 128),
            nn.ReLU(inplace=True),
            nn.Linear(128, num_classes)
        )
    
    def forward(self, x):
        x = self.conv_layers(x)
        x = x.view(x.size(0), -1)  # Flatten
        x = self.classifier(x)
        return x

# Model instantiation
model = CNNClassifier(num_classes=10)
print(f"Total parameters: {sum(p.numel() for p in model.parameters()):,}")

# Example forward pass
dummy_input = torch.randn(1, 3, 32, 32)  # Batch=1, Channels=3, Height=32, Width=32
output = model(dummy_input)
print(f"Output shape: {output.shape}")  # Should be [1, 10]
                </div>
            </div>
        </div>

        <!-- Parameters Configuration Section -->
        <div id="parameters" class="content-section">
            <h2 class="section-title">⚙️ Network Parameters Configuration</h2>
            
            <div class="highlight">
                <h3>🎯 Key Parameters for Different Architectures</h3>
                <p>Understanding and properly setting parameters is crucial for successful deep learning model training.</p>
            </div>

            <div class="cards-grid">
                <!-- ANN Parameters -->
                <div class="card">
                    <h3>🧠 Artificial Neural Network (ANN) Parameters</h3>
                    <h4>🏗️ Architecture Parameters:</h4>
                    <ul>
                        <li><strong>Input Size:</strong> Number of input features</li>
                        <li><strong>Hidden Layers:</strong> Number and size of hidden layers</li>
                        <li><strong>Output Size:</strong> Number of output neurons</li>
                        <li><strong>Activation Functions:</strong> ReLU, Sigmoid, Tanh</li>
                    </ul>
                    
                    <h4>🎯 Training Parameters:</h4>
                    <ul>
                        <li><strong>Learning Rate:</strong> 0.001 - 0.1 (Adam: 0.001)</li>
                        <li><strong>Batch Size:</strong> 16, 32, 64, 128</li>
                        <li><strong>Epochs:</strong> 50-1000</li>
                        <li><strong>Dropout Rate:</strong> 0.2 - 0.5</li>
                    </ul>
                    
                    <div class="code-block">
# ANN Configuration Example
ann_config = {
    'input_size': 784,           # MNIST: 28x28
    'hidden_layers': [256, 128, 64],
    'output_size': 10,           # 10 classes
    'activation': 'relu',        # ReLU activation
    'dropout_rate': 0.3,         # 30% dropout
    'learning_rate': 0.001,      # Adam optimizer
    'batch_size': 32,            # Batch size
    'epochs': 100,               # Training epochs
    'weight_decay': 1e-4         # L2 regularization
}
                    </div>
                </div>

                <!-- CNN Parameters -->
                <div class="card">
                    <h3>🖼️ Convolutional Neural Network (CNN) Parameters</h3>
                    <h4>🔍 Convolution Parameters:</h4>
                    <ul>
                        <li><strong>Filters/Kernels:</strong> 16, 32, 64, 128, 256</li>
                        <li><strong>Kernel Size:</strong> 3×3, 5×5, 7×7</li>
                        <li><strong>Stride:</strong> 1, 2 (step size)</li>
                        <li><strong>Padding:</strong> 'same', 'valid'</li>
                    </ul>
                    
                    <h4>📉 Pooling Parameters:</h4>
                    <ul>
                        <li><strong>Pool Size:</strong> 2×2, 3×3</li>
                        <li><strong>Pool Type:</strong> MaxPool, AvgPool</li>
                        <li><strong>Stride:</strong> Usually same as pool size</li>
                    </ul>
                    
                    <div class="code-block">
# CNN Configuration Example
cnn_config = {
    'input_shape': (32, 32, 3),     # CIFAR-10: 32x32x3
    'conv_layers': [
        {'filters': 32, 'kernel_size': 3, 'stride': 1, 'padding': 'same'},
        {'filters': 64, 'kernel_size': 3, 'stride': 1, 'padding': 'same'},
        {'filters': 128, 'kernel_size': 3, 'stride': 1, 'padding': 'same'}
    ],
    'pooling': {'size': 2, 'type': 'max'},
    'dense_layers': [512, 256],      # Fully connected layers
    'output_size': 10,               # Number of classes
    'dropout_rate': 0.5,             # Higher for CNNs
    'learning_rate': 0.001,          # Start with 0.001
    'batch_size': 32,                # Common choice
    'epochs': 50,                    # Usually fewer than ANN
    'data_augmentation': True        # Important for CNNs
}
                    </div>
                </div>

                <!-- RNN Parameters -->
                <div class="card">
                    <h3>🔄 Recurrent Neural Network (RNN) Parameters</h3>
                    <h4>🔄 Sequence Parameters:</h4>
                    <ul>
                        <li><strong>Sequence Length:</strong> 10-1000 timesteps</li>
                        <li><strong>Input Size:</strong> Feature dimension per timestep</li>
                        <li><strong>Hidden Size:</strong> 50, 100, 200, 512</li>
                        <li><strong>Number of Layers:</strong> 1-4 layers</li>
                    </ul>
                    
                    <h4>🎛️ Training Parameters:</h4>
                    <ul>
                        <li><strong>Gradient Clipping:</strong> 1.0 - 5.0</li>
                        <li><strong>Learning Rate:</strong> 0.001 - 0.01</li>
                        <li><strong>Batch Size:</strong> 16-64 (smaller for sequences)</li>
                    </ul>
                    
                    <div class="code-block">
# RNN Configuration Example
rnn_config = {
    'input_size': 100,              # Word embedding dimension
    'hidden_size': 128,             # RNN hidden state size
    'num_layers': 2,                # Number of RNN layers
    'sequence_length': 50,          # Max sequence length
    'output_size': 1,               # Binary classification
    'dropout_rate': 0.3,            # Between RNN layers
    'learning_rate': 0.01,          # Higher than CNN/ANN
    'batch_size': 16,               # Smaller batches
    'epochs': 20,                   # Faster convergence
    'gradient_clip': 1.0,           # Prevent exploding gradients
    'bidirectional': False          # Forward only
}
                    </div>
                </div>

                <!-- LSTM Parameters -->
                <div class="card">
                    <h3>🔐 Long Short-Term Memory (LSTM) Parameters</h3>
                    <h4>🧠 Memory Parameters:</h4>
                    <ul>
                        <li><strong>Hidden Size:</strong> 50, 100, 256, 512</li>
                        <li><strong>Cell State Size:</strong> Same as hidden size</li>
                        <li><strong>Forget Gate Bias:</strong> Initialize to 1.0</li>
                        <li><strong>Bidirectional:</strong> True/False</li>
                    </ul>
                    
                    <h4>🎯 Advanced Parameters:</h4>
                    <ul>
                        <li><strong>Attention Mechanism:</strong> Optional</li>
                        <li><strong>Teacher Forcing:</strong> For sequence-to-sequence</li>
                        <li><strong>Beam Search:</strong> For inference</li>
                    </ul>
                    
                    <div class="code-block">
# LSTM Configuration Example
lstm_config = {
    'input_size': 300,              # GloVe embeddings
    'hidden_size': 256,             # LSTM hidden state
    'num_layers': 2,                # Stacked LSTMs
    'sequence_length': 100,         # Longer sequences
    'output_size': 5,               # Multi-class classification
    'dropout_rate': 0.4,            # Higher dropout
    'learning_rate': 0.005,         # Moderate learning rate
    'batch_size': 32,               # Standard batch size
    'epochs': 30,                   # More epochs needed
    'gradient_clip': 2.0,           # Larger clip value
    'bidirectional': True,          # Better performance
    'attention': False,             # Add if needed
    'weight_decay': 1e-5           # Light regularization
}
                    </div>
                </div>
            </div>

            <button class="collapsible">🛠️ Hands-on Parameter Implementation</button>
            <div class="collapsible-content">
                <h4>Complete Parameter Configuration Class:</h4>
                <div class="code-block">
import torch
import torch.nn as nn
from typing import Dict, List, Any

class ModelConfigurator:
    """Utility class for managing deep learning model parameters"""
    
    @staticmethod
    def get_ann_config(task_type: str = 'classification') -> Dict[str, Any]:
        """Get optimized ANN configuration based on task type"""
        base_config = {
            'input_size': 784,
            'hidden_layers': [256, 128, 64],
            'dropout_rate': 0.3,
            'learning_rate': 0.001,
            'batch_size': 32,
            'epochs': 100,
            'optimizer': 'adam',
            'weight_decay': 1e-4
        }
        
        if task_type == 'classification':
            base_config.update({
                'output_size': 10,
                'loss_function': 'cross_entropy',
                'activation': 'relu',
                'output_activation': 'softmax'
            })
        elif task_type == 'regression':
            base_config.update({
                'output_size': 1,
                'loss_function': 'mse',
                'activation': 'relu',
                'output_activation': 'linear'
            })
        
        return base_config
    
    @staticmethod
    def get_cnn_config(image_size: tuple = (32, 32, 3)) -> Dict[str, Any]:
        """Get optimized CNN configuration based on image size"""
        return {
            'input_shape': image_size,
            'conv_layers': [
                {'filters': 32, 'kernel_size': 3, 'stride': 1, 'padding': 1},
                {'filters': 64, 'kernel_size': 3, 'stride': 1, 'padding': 1},
                {'filters': 128, 'kernel_size': 3, 'stride': 1, 'padding': 1}
            ],
            'pooling': {'size': 2, 'stride': 2, 'type': 'max'},
            'batch_norm': True,
            'dense_layers': [512, 256],
            'output_size': 10,
            'dropout_rate': 0.5,
            'learning_rate': 0.001,
            'batch_size': 32,
            'epochs': 50,
            'data_augmentation': {
                'horizontal_flip': True,
                'rotation': 15,
                'zoom': 0.1,
                'width_shift': 0.1,
                'height_shift': 0.1
            }
        }
    
    @staticmethod
    def get_lstm_config(vocab_size: int, embedding_dim: int = 300) -> Dict[str, Any]:
        """Get optimized LSTM configuration for NLP tasks"""
        return {
            'vocab_size': vocab_size,
            'embedding_dim': embedding_dim,
            'hidden_size': 256,
            'num_layers': 2,
            'sequence_length': 100,
            'output_size': 2,  # Binary sentiment
            'dropout_rate': 0.4,
            'learning_rate': 0.005,
            'batch_size': 32,
            'epochs': 30,
            'gradient_clip': 2.0,
            'bidirectional': True,
            'pretrained_embeddings': True,
            'freeze_embeddings': False,
            'attention': False
        }
    
    @staticmethod
    def optimize_for_hardware(config: Dict[str, Any], device: str) -> Dict[str, Any]:
        """Optimize configuration based on available hardware"""
        if device == 'cpu':
            # Reduce batch size and model complexity for CPU
            config['batch_size'] = min(config['batch_size'], 16)
            if 'hidden_layers' in config:
                config['hidden_layers'] = [size // 2 for size in config['hidden_layers']]
        elif device == 'gpu':
            # Increase batch size for GPU if memory allows
            config['batch_size'] = min(config['batch_size'] * 2, 128)
        
        return config

# Usage example
configurator = ModelConfigurator()

# Get configurations for different models
ann_config = configurator.get_ann_config('classification')
cnn_config = configurator.get_cnn_config((224, 224, 3))  # ImageNet size
lstm_config = configurator.get_lstm_config(vocab_size=10000)

# Optimize for hardware
device = 'gpu' if torch.cuda.is_available() else 'cpu'
ann_config = configurator.optimize_for_hardware(ann_config, device)

print("ANN Config:", ann_config)
print("CNN Config:", cnn_config)
print("LSTM Config:", lstm_config)
                </div>
            </div>

            <button class="collapsible">📊 Parameter Tuning Best Practices</button>
            <div class="collapsible-content">
                <h4>Systematic Parameter Tuning Approach:</h4>
                <div class="code-block">
# Hyperparameter tuning with Optuna (example)
import optuna

def objective(trial):
    # Suggest hyperparameters
    lr = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)
    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])
    hidden_size = trial.suggest_int('hidden_size', 64, 512, step=64)
    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.7)
    
    # Build and train model with suggested parameters
    model = build_model(lr, batch_size, hidden_size, dropout_rate)
    accuracy = train_and_evaluate(model)
    
    return accuracy

# Run optimization
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)

print("Best parameters:", study.best_params)
                </div>
                
                <h4>Common Parameter Ranges:</h4>
                <ul>
                    <li><strong>Learning Rate:</strong> Start with 0.001, try [0.1, 0.01, 0.001, 0.0001]</li>
                    <li><strong>Batch Size:</strong> Powers of 2: [16, 32, 64, 128]</li>
                    <li><strong>Hidden Units:</strong> Powers of 2: [64, 128, 256, 512]</li>
                    <li><strong>Dropout:</strong> Start with 0.3, range [0.1, 0.7]</li>
                    <li><strong>Epochs:</strong> Use early stopping, max 100-1000</li>
                </ul>
            </div>
        </div>

        <!-- Large Language Models Section -->
        <div id="llm" class="content-section">
            <h2 class="section-title">🤖 Large Language Models (LLMs)</h2>
            
            <div class="highlight">
                <h3>🎯 What are Large Language Models?</h3>
                <p>LLMs are transformer-based neural networks trained on massive text datasets to understand and generate human-like text. They represent the current state-of-the-art in NLP and are the foundation of modern AI assistants.</p>
            </div>

            <div class="interactive-demo">
                <h3>🏗️ LLM Architecture Evolution</h3>
                <div class="pipeline-visual">
                    <div class="pipeline-step">
                        <h4>📚 GPT-1 (2018)</h4>
                        <p>117M parameters<br>Decoder-only transformer</p>
                    </div>
                    <div class="pipeline-arrow">→</div>
                    <div class="pipeline-step">
                        <h4>🚀 GPT-2 (2019)</h4>
                        <p>1.5B parameters<br>Unsupervised pre-training</p>
                    </div>
                    <div class="pipeline-arrow">→</div>
                    <div class="pipeline-step">
                        <h4>🔥 GPT-3 (2020)</h4>
                        <p>175B parameters<br>Few-shot learning</p>
                    </div>
                    <div class="pipeline-arrow">→</div>
                    <div class="pipeline-step">
                        <h4>💎 GPT-4 (2023)</h4>
                        <p>~1.7T parameters<br>Multimodal capabilities</p>
                    </div>
                    <div class="pipeline-arrow">→</div>
                    <div class="pipeline-step">
                        <h4>🌟 2025 Models</h4>
                        <p>Advanced reasoning<br>Specialized domains</p>
                    </div>
                </div>
            </div>

            <div class="cards-grid">
                <div class="card">
                    <h3>🧠 LLM Architecture Components</h3>
                    <h4>🔑 Key Components:</h4>
                    <ul>
                        <li><strong>Transformer Blocks:</strong> Self-attention + Feed-forward</li>
                        <li><strong>Attention Heads:</strong> 12-96 heads for different aspects</li>
                        <li><strong>Position Encoding:</strong> Understanding word order</li>
                        <li><strong>Layer Normalization:</strong> Stable training</li>
                        <li><strong>Tokenization:</strong> Breaking text into tokens</li>
                    </ul>
                    
                    <div class="code-block">
# Simplified Transformer Block
import torch
import torch.nn as nn

class TransformerBlock(nn.Module):
    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):
        super().__init__()
        self.attention = nn.MultiheadAttention(
            embed_dim, num_heads, dropout=dropout
        )
        self.norm1 = nn.LayerNorm(embed_dim)
        self.norm2 = nn.LayerNorm(embed_dim)
        
        self.feed_forward = nn.Sequential(
            nn.Linear(embed_dim, ff_dim),
            nn.ReLU(),
            nn.Linear(ff_dim, embed_dim),
            nn.Dropout(dropout)
        )
    
    def forward(self, x):
        # Self-attention with residual connection
        attn_out, _ = self.attention(x, x, x)
        x = self.norm1(x + attn_out)
        
        # Feed-forward with residual connection
        ff_out = self.feed_forward(x)
        x = self.norm2(x + ff_out)
        
        return x
                    </div>
                </div>

                <div class="card">
                    <h3>📊 Popular LLM Families (2025)</h3>
                    <div class="trending-models">
                        <div class="model-card" style="margin: 10px 0;">
                            <h4>🔴 GPT Series (OpenAI)</h4>
                            <p><strong>GPT-4:</strong> Multimodal, reasoning, coding</p>
                            <p><strong>Applications:</strong> ChatGPT, API services</p>
                        </div>
                        
                        <div class="model-card" style="margin: 10px 0;">
                            <h4>🔵 Gemini (Google)</h4>
                            <p><strong>Features:</strong> Math, science, multimodal</p>
                            <p><strong>Applications:</strong> Bard, Google services</p>
                        </div>
                        
                        <div class="model-card" style="margin: 10px 0;">
                            <h4>🟣 Claude (Anthropic)</h4>
                            <p><strong>Features:</strong> Constitutional AI, safety</p>
                            <p><strong>Applications:</strong> Helpful assistant, analysis</p>
                        </div>
                        
                        <div class="model-card" style="margin: 10px 0;">
                            <h4>🟠 LLaMA (Meta)</h4>
                            <p><strong>Features:</strong> Open-source, efficient</p>
                            <p><strong>Applications:</strong> Research, fine-tuning</p>
                        </div>
                    </div>
                </div>

                <div class="card">
                    <h3>🛠️ Building a Simple Language Model</h3>
                    <div class="code-block">
import torch
import torch.nn as nn
from transformers import GPT2Tokenizer

class SimpleLM(nn.Module):
    def __init__(self, vocab_size, embed_dim=512, num_heads=8, 
                 num_layers=6, max_seq_len=1024):
        super().__init__()
        self.embed_dim = embed_dim
        self.max_seq_len = max_seq_len
        
        # Token and position embeddings
        self.token_embedding = nn.Embedding(vocab_size, embed_dim)
        self.position_embedding = nn.Embedding(max_seq_len, embed_dim)
        
        # Transformer layers
        self.transformer_layers = nn.ModuleList([
            TransformerBlock(embed_dim, num_heads, embed_dim * 4)
            for _ in range(num_layers)
        ])
        
        # Output layer
        self.norm = nn.LayerNorm(embed_dim)
        self.output = nn.Linear(embed_dim, vocab_size)
        
    def forward(self, input_ids):
        seq_len = input_ids.size(1)
        
        # Create position indices
        positions = torch.arange(seq_len, device=input_ids.device)
        
        # Embeddings
        token_embeds = self.token_embedding(input_ids)
        pos_embeds = self.position_embedding(positions)
        x = token_embeds + pos_embeds
        
        # Transformer layers
        for layer in self.transformer_layers:
            x = layer(x)
        
        # Output projection
        x = self.norm(x)
        logits = self.output(x)
        
        return logits

# Example usage
tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
vocab_size = tokenizer.vocab_size

model = SimpleLM(vocab_size=vocab_size)
print(f"Model parameters: {sum(p.numel() for p in model.parameters()):,}")

# Generate text (simplified)
def generate_text(model, tokenizer, prompt, max_length=50):
    model.eval()
    tokens = tokenizer.encode(prompt, return_tensors='pt')
    
    with torch.no_grad():
        for _ in range(max_length):
            logits = model(tokens)
            next_token = torch.argmax(logits[0, -1, :])
            tokens = torch.cat([tokens, next_token.unsqueeze(0).unsqueeze(0)], dim=1)
            
            if next_token == tokenizer.eos_token_id:
                break
    
    return tokenizer.decode(tokens[0])
                    </div>
                </div>

                <div class="card">
                    <h3>🎯 LLM Training Process</h3>
                    <h4>📚 Training Stages:</h4>
                    <ol>
                        <li><strong>Pre-training:</strong> Learn language patterns from massive text</li>
                        <li><strong>Fine-tuning:</strong> Adapt to specific tasks or domains</li>
                        <li><strong>RLHF:</strong> Align with human preferences and values</li>
                        <li><strong>Deployment:</strong> Optimize for inference and safety</li>
                    </ol>
                    
                    <h4>💰 Resource Requirements:</h4>
                    <ul>
                        <li><strong>GPT-3 Scale:</strong> ~$4M training cost, 300+ GPUs</li>
                        <li><strong>Data:</strong> 300B+ tokens from web, books, papers</li>
                        <li><strong>Time:</strong> Weeks to months of continuous training</li>
                        <li><strong>Infrastructure:</strong> Distributed training across clusters</li>
                    </ul>
                </div>
            </div>

            <button class="collapsible">🚀 Advanced LLM Techniques (2025)</button>
            <div class="collapsible-content">
                <h4>🧠 Mixture of Experts (MoE):</h4>
                <div class="code-block">
# Simplified Mixture of Experts implementation
class MixtureOfExperts(nn.Module):
    def __init__(self, embed_dim, num_experts=8, expert_dim=2048):
        super().__init__()
        self.num_experts = num_experts
        
        # Router network (gating)
        self.router = nn.Linear(embed_dim, num_experts)
        
        # Expert networks
        self.experts = nn.ModuleList([
            nn.Sequential(
                nn.Linear(embed_dim, expert_dim),
                nn.ReLU(),
                nn.Linear(expert_dim, embed_dim)
            ) for _ in range(num_experts)
        ])
    
    def forward(self, x):
        # Route to experts
        router_weights = torch.softmax(self.router(x), dim=-1)
        
        # Compute expert outputs
        expert_outputs = torch.stack([
            expert(x) for expert in self.experts
        ], dim=-1)
        
        # Weighted combination
        output = torch.sum(
            expert_outputs * router_weights.unsqueeze(-2), 
            dim=-1
        )
        
        return output
                </div>
                
                <h4>🎯 Retrieval-Augmented Generation (RAG):</h4>
                <div class="code-block">
# RAG implementation concept
class RAGModel:
    def __init__(self, llm, retriever, knowledge_base):
        self.llm = llm
        self.retriever = retriever
        self.knowledge_base = knowledge_base
    
    def generate_response(self, query):
        # 1. Retrieve relevant documents
        relevant_docs = self.retriever.search(
            query, self.knowledge_base, top_k=5
        )
        
        # 2. Construct augmented prompt
        context = "\n".join(relevant_docs)
        augmented_prompt = f"""
        Context: {context}
        
        Question: {query}
        
        Answer based on the context:
        """
        
        # 3. Generate response with LLM
        response = self.llm.generate(augmented_prompt)
        
        return response, relevant_docs
                </div>
                
                <h4>🔧 Fine-tuning Techniques:</h4>
                <ul>
                    <li><strong>LoRA (Low-Rank Adaptation):</strong> Efficient parameter updates</li>
                    <li><strong>Prompt Tuning:</strong> Learn optimal prompts</li>
                    <li><strong>Instruction Tuning:</strong> Follow human instructions</li>
                    <li><strong>Constitutional AI:</strong> Self-improvement through critique</li>
                </ul>
            </div>

            <button class="collapsible">💡 LLM Applications & Use Cases</button>
            <div class="collapsible-content">
                <h4>🌟 Current Applications (2025):</h4>
                <div class="cards-grid" style="margin: 20px 0;">
                    <div style="background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 10px;">
                        <h5>💼 Business Applications</h5>
                        <ul>
                            <li>Customer service chatbots</li>
                            <li>Content generation and marketing</li>
                            <li>Code generation and debugging</li>
                            <li>Document analysis and summarization</li>
                        </ul>
                    </div>
                    
                    <div style="background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 10px;">
                        <h5>🔬 Research & Education</h5>
                        <ul>
                            <li>Scientific paper analysis</li>
                            <li>Personalized tutoring</li>
                            <li>Language translation</li>
                            <li>Creative writing assistance</li>
                        </ul>
                    </div>
                    
                    <div style="background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 10px;">
                        <h5>🏥 Specialized Domains</h5>
                        <ul>
                            <li>Medical diagnosis assistance</li>
                            <li>Legal document review</li>
                            <li>Financial analysis</li>
                            <li>Software engineering</li>
                        </ul>
                    </div>
                </div>
                
                <h4>🚀 Emerging Trends (2025):</h4>
                <ul>
                    <li><strong>Multimodal LLMs:</strong> Understanding images, audio, video</li>
                    <li><strong>Autonomous Agents:</strong> LLMs that can use tools and APIs</li>
                    <li><strong>Specialized Models:</strong> Domain-specific LLMs (medicine, law, etc.)</li>
                    <li><strong>Efficient Models:</strong> Smaller models with comparable performance</li>
                    <li><strong>Real-time Inference:</strong> Faster response times and edge deployment</li>
                </ul>
            </div>
        </div>

        <!-- CNN Basics Section -->
        <div id="cnn-basics" class="content-section">
            <h2 class="section-title">🖼️ Convolutional Neural Networks (CNNs)</h2>
            
            <div class="highlight">
                <h3>🎯 What are CNNs?</h3>
                <p>CNNs are specialized neural networks designed for processing grid-like data such as images. They use mathematical operations called convolutions to detect features like edges, shapes, and textures automatically.</p>
            </div>

            <div class="interactive-demo">
                <h3>🏗️ CNN Architecture Components</h3>
                <div class="pipeline-visual">
                    <div class="pipeline-step">
                        <h4>📷 Input Image</h4>
                        <p>Raw pixel data<br>(Height × Width × Channels)</p>
                    </div>
                    <div class="pipeline-arrow">→</div>
                    <div class="pipeline-step">
                        <h4>🔍 Convolution Layer</h4>
                        <p>Feature detection<br>using filters/kernels</p>
                    </div>
                    <div class="pipeline-arrow">→</div>
                    <div class="pipeline-step">
                        <h4>📉 Pooling Layer</h4>
                        <p>Dimensionality reduction<br>Max/Average pooling</p>
                    </div>
                    <div class="pipeline-arrow">→</div>
                    <div class="pipeline-step">
                        <h4>🔄 More Conv+Pool</h4>
                        <p>Multiple layers for<br>complex features</p>
                    </div>
                    <div class="pipeline-arrow">→</div>
                    <div class="pipeline-step">
                        <h4>📊 Fully Connected</h4>
                        <p>Classification<br>Dense layers</p>
                    </div>
                </div>
            </div>

            <div class="cards-grid">
                <div class="card">
                    <h3>🔍 Convolution Operation</h3>
                    <p><strong>Purpose:</strong> Detect features like edges, corners, textures</p>
                    <p><strong>How it works:</strong> Slide a small filter (kernel) across the image</p>
                    <p><strong>Filter examples:</strong></p>
                    <div class="code-block">
# Edge detection filter (3x3)
edge_filter = [
    [-1, -1, -1],
    [-1,  8, -1],
    [-1, -1, -1]
]

# Blur filter (3x3)
blur_filter = [
    [1/9, 1/9, 1/9],
    [1/9, 1/9, 1/9],
    [1/9, 1/9, 1/9]
]
                    </div>
                </div>

                <div class="card">
                    <h3>📉 Pooling Layer</h3>
                    <p><strong>Purpose:</strong> Reduce spatial dimensions and computational cost</p>
                    <p><strong>Types:</strong></p>
                    <ul>
                        <li><strong>Max Pooling:</strong> Takes maximum value in each region</li>
                        <li><strong>Average Pooling:</strong> Takes average value in each region</li>
                        <li><strong>Global Pooling:</strong> Reduces entire feature map to single value</li>
                    </ul>
                    <p><strong>Benefits:</strong> Translation invariance, overfitting reduction</p>
                </div>

                <div class="card">
                    <h3>⚙️ Key Parameters</h3>
                    <p><strong>Filter Size:</strong> Usually 3×3 or 5×5</p>
                    <p><strong>Stride:</strong> Step size when moving filter (1, 2, etc.)</p>
                    <p><strong>Padding:</strong> Add zeros around image border</p>
                    <p><strong>Number of Filters:</strong> How many features to detect per layer</p>
                    <div class="code-block">
# CNN layer parameters
Conv2D(
    filters=32,        # Number of filters
    kernel_size=(3,3), # Filter size
    stride=(1,1),      # Step size
    padding='same',    # Padding type
    activation='relu'  # Activation function
)
                    </div>
                </div>
            </div>

            <button class="collapsible">🎯 CNN Step-by-Step Example</button>
            <div class="collapsible-content">
                <h4>Let's trace through a simple CNN:</h4>
                <div class="code-block">
import numpy as np

# 1. Input Image (simplified 5x5 grayscale)
input_image = np.array([
    [1, 1, 1, 0, 0],
    [0, 1, 1, 1, 0],
    [0, 0, 1, 1, 1],
    [0, 0, 1, 1, 0],
    [0, 1, 1, 0, 0]
])

# 2. Define a 3x3 edge detection filter
filter_kernel = np.array([
    [-1, -1, -1],
    [-1,  8, -1],
    [-1, -1, -1]
])

# 3. Convolution operation (simplified)
def convolution_2d(image, kernel):
    kernel_height, kernel_width = kernel.shape
    image_height, image_width = image.shape
    
    # Output size calculation
    output_height = image_height - kernel_height + 1
    output_width = image_width - kernel_width + 1
    
    # Initialize output
    output = np.zeros((output_height, output_width))
    
    # Perform convolution
    for i in range(output_height):
        for j in range(output_width):
            # Element-wise multiplication and sum
            output[i, j] = np.sum(
                image[i:i+kernel_height, j:j+kernel_width] * kernel
            )
    
    return output

# Apply convolution
feature_map = convolution_2d(input_image, filter_kernel)
print("Feature map shape:", feature_map.shape)
print("Feature map:")
print(feature_map)

# 4. Apply ReLU activation
activated_features = np.maximum(0, feature_map)

# 5. Apply Max Pooling (2x2)
def max_pooling_2d(feature_map, pool_size=2):
    pool_height, pool_width = pool_size, pool_size
    feature_height, feature_width = feature_map.shape
    
    output_height = feature_height // pool_height
    output_width = feature_width // pool_width
    
    output = np.zeros((output_height, output_width))
    
    for i in range(output_height):
        for j in range(output_width):
            # Take maximum in each pool region
            pool_region = feature_map[
                i*pool_height:(i+1)*pool_height,
                j*pool_width:(j+1)*pool_width
            ]
            output[i, j] = np.max(pool_region)
    
    return output

pooled_features = max_pooling_2d(activated_features)
print("After pooling:", pooled_features.shape)
                </div>
            </div>

            <button class="collapsible">🏗️ Complete CNN Implementation</button>
            <div class="collapsible-content">
                <h4>Building a CNN for Image Classification:</h4>
                <div class="code-block">
import tensorflow as tf
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt

# 1. Define CNN Architecture
def create_cnn_model(input_shape, num_classes):
    model = models.Sequential([
        # First Convolutional Block
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        
        # Second Convolutional Block
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        
        # Third Convolutional Block
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        
        # Flatten and Dense Layers
        layers.Flatten(),
        layers.Dense(512, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation='softmax')
    ])
    
    return model

# 2. Create and compile model
model = create_cnn_model(input_shape=(32, 32, 3), num_classes=10)

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# 3. Model summary
model.summary()

# 4. Training setup with callbacks
callbacks = [
    tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),
    tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5),
    tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True)
]

# 5. Train the model (example with CIFAR-10)
# history = model.fit(
#     x_train, y_train,
#     batch_size=32,
#     epochs=100,
#     validation_data=(x_val, y_val),
#     callbacks=callbacks
# )

# 6. Visualize CNN filters (first layer)
def visualize_filters(model, layer_name, num_filters=8):
    # Get the weights of the specified layer
    layer = model.get_layer(layer_name)
    filters, biases = layer.get_weights()
    
    # Normalize filters for visualization
    f_min, f_max = filters.min(), filters.max()
    filters = (filters - f_min) / (f_max - f_min)
    
    # Plot filters
    fig, axes = plt.subplots(2, num_filters//2, figsize=(15, 6))
    for i in range(num_filters):
        ax = axes[i//4, i%4]
        ax.imshow(filters[:, :, 0, i], cmap='gray')
        ax.set_title(f'Filter {i+1}')
        ax.axis('off')
    
    plt.tight_layout()
    plt.show()

# Visualize learned filters
# visualize_filters(model, 'conv2d', 8)
                </div>
            </div>

            <div class="trending-models">
                <div class="model-card">
                    <h3>🔥 Popular CNN Architectures</h3>
                    <p><strong>LeNet-5 (1998):</strong> First successful CNN</p>
                    <p><strong>AlexNet (2012):</strong> ImageNet breakthrough</p>
                    <p><strong>VGG (2014):</strong> Deep networks with small filters</p>
                    <p><strong>ResNet (2015):</strong> Skip connections, very deep</p>
                    <p><strong>EfficientNet (2019):</strong> Optimized scaling</p>
                </div>

                <div class="model-card">
                    <h3>🎯 CNN Applications</h3>
                    <p><strong>Image Classification:</strong> Object recognition</p>
                    <p><strong>Object Detection:</strong> YOLO, R-CNN</p>
                    <p><strong>Medical Imaging:</strong> X-ray, MRI analysis</p>
                    <p><strong>Autonomous Vehicles:</strong> Road scene understanding</p>
                    <p><strong>Security:</strong> Face recognition, surveillance</p>
                </div>

                <div class="model-card">
                    <h3>⚡ CNN Optimization Tips</h3>
                    <p><strong>Data Augmentation:</strong> Rotation, flip, zoom</p>
                    <p><strong>Transfer Learning:</strong> Use pre-trained models</p>
                    <p><strong>Batch Normalization:</strong> Faster convergence</p>
                    <p><strong>Dropout:</strong> Prevent overfitting</p>
                    <p><strong>Learning Rate Scheduling:</strong> Adaptive rates</p>
                </div>
            </div>

            <div class="code-block">
# Quick CNN implementation with transfer learning
import tensorflow as tf
from tensorflow.keras.applications import ResNet50

# Use pre-trained ResNet50 as base
base_model = ResNet50(
    weights='imagenet',  # Pre-trained weights
    include_top=False,   # Exclude final classification layer
    input_shape=(224, 224, 3)
)

# Freeze base model layers
base_model.trainable = False

# Add custom classification head
model = tf.keras.Sequential([
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(num_classes, activation='softmax')
])

# Compile and train
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

print("Transfer learning model ready!")
            </div>
        </div>

        <!-- Pipeline Section -->
        <div id="pipeline" class="content-section">
            <h2 class="section-title">Deep Learning Pipeline</h2>
            
            <div class="pipeline-visual">
                <div class="pipeline-step">
                    <h3>📥 Data Collection</h3>
                    <p>Gather raw data from various sources</p>
                </div>
                <div class="pipeline-arrow">→</div>
                <div class="pipeline-step">
                    <h3>🧹 Data Preprocessing</h3>
                    <p>Clean, normalize, and augment data</p>
                </div>
                <div class="pipeline-arrow">→</div>
                <div class="pipeline-step">
                    <h3>🏗️ Model Design</h3>
                    <p>Choose architecture and hyperparameters</p>
                </div>
                <div class="pipeline-arrow">→</div>
                <div class="pipeline-step">
                    <h3>🎯 Training</h3>
                    <p>Fit model to training data</p>
                </div>
                <div class="pipeline-arrow">→</div>
                <div class="pipeline-step">
                    <h3>✅ Evaluation</h3>
                    <p>Test model performance</p>
                </div>
                <div class="pipeline-arrow">→</div>
                <div class="pipeline-step">
                    <h3>🚀 Deployment</h3>
                    <p>Deploy to production</p>
                </div>
            </div>

            <div class="cards-grid">
                <div class="card">
                    <h3>📥 Data Preprocessing</h3>
                    <div class="code-block">
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler

# Load and clean data
data = pd.read_csv('dataset.csv')
data = data.dropna()  # Remove missing values

# Normalize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split data
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)
                    </div>
                </div>

                <div class="card">
                    <h3>🏗️ Model Architecture</h3>
                    <div class="code-block">
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

# Build neural network
model = Sequential([
    Dense(128, activation='relu', input_shape=(input_dim,)),
    Dropout(0.3),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')  # Binary classification
])

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)
                    </div>
                </div>

                <div class="card">
                    <h3>🎯 Training & Validation</h3>
                    <div class="code-block">
# Train the model
history = model.fit(
    X_train, y_train,
    batch_size=32,
    epochs=100,
    validation_data=(X_val, y_val),
    callbacks=[
        tf.keras.callbacks.EarlyStopping(patience=10),
        tf.keras.callbacks.ReduceLROnPlateau(factor=0.5)
    ]
)

# Evaluate performance
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_accuracy:.4f}")
                    </div>
                </div>
            </div>

            <button class="collapsible">🛠️ Best Practices</button>
            <div class="collapsible-content">
                <h4>Data Management:</h4>
                <ul>
                    <li>Always validate data quality before training</li>
                    <li>Use proper train/validation/test splits (70/15/15)</li>
                    <li>Apply data augmentation for small datasets</li>
                    <li>Handle class imbalance with appropriate techniques</li>
                </ul>
                <h4>Model Development:</h4>
                <ul>
                    <li>Start with simple models and gradually increase complexity</li>
                    <li>Use early stopping to prevent overfitting</li>
                    <li>Monitor both training and validation metrics</li>
                    <li>Save model checkpoints during training</li>
                </ul>
            </div>
        </div>

        <!-- Models Section -->
        <div id="models" class="content-section">
            <h2 class="section-title">Popular Deep Learning Models</h2>
            
            <div class="trending-models">
                <div class="model-card">
                    <h3>🖼️ Convolutional Neural Networks (CNNs)</h3>
                    <p><strong>Best for:</strong> Computer Vision, Image Recognition</p>
                    <p><strong>Key Features:</strong> Convolution layers, pooling, spatial hierarchy</p>
                    <p><strong>Applications:</strong> Image classification, object detection, medical imaging</p>
                    <div class="progress-bar">
                        <div class="progress-fill" style="width: 95%"></div>
                    </div>
                    <small>Popularity: 95%</small>
                </div>

                <div class="model-card">
                    <h3>🔄 Recurrent Neural Networks (RNNs/LSTMs)</h3>
                    <p><strong>Best for:</strong> Sequential Data, Time Series</p>
                    <p><strong>Key Features:</strong> Memory cells, gate mechanisms</p>
                    <p><strong>Applications:</strong> Speech recognition, machine translation, stock prediction</p>
                    <div class="progress-bar">
                        <div class="progress-fill" style="width: 80%"></div>
                    </div>
                    <small>Popularity: 80%</small>
                </div>

                <div class="model-card">
                    <h3>🤖 Transformers</h3>
                    <p><strong>Best for:</strong> Natural Language Processing</p>
                    <p><strong>Key Features:</strong> Self-attention, parallel processing</p>
                    <p><strong>Applications:</strong> ChatGPT, BERT, language models</p>
                    <div class="progress-bar">
                        <div class="progress-fill" style="width: 98%"></div>
                    </div>
                    <small>Popularity: 98% (2025 Leader)</small>
                </div>

                <div class="model-card">
                    <h3>🎨 Generative Adversarial Networks (GANs)</h3>
                    <p><strong>Best for:</strong> Data Generation, Creative AI</p>
                    <p><strong>Key Features:</strong> Generator vs. Discriminator</p>
                    <p><strong>Applications:</strong> Image synthesis, deepfakes, art generation</p>
                    <div class="progress-bar">
                        <div class="progress-fill" style="width: 85%"></div>
                    </div>
                    <small>Popularity: 85%</small>
                </div>

                <div class="model-card">
                    <h3>🧠 Autoencoders</h3>
                    <p><strong>Best for:</strong> Dimensionality Reduction, Anomaly Detection</p>
                    <p><strong>Key Features:</strong> Encoder-decoder architecture</p>
                    <p><strong>Applications:</strong> Data compression, denoising, feature learning</p>
                    <div class="progress-bar">
                        <div class="progress-fill" style="width: 70%"></div>
                    </div>
                    <small>Popularity: 70%</small>
                </div>

                <div class="model-card">
                    <h3>🎮 Reinforcement Learning</h3>
                    <p><strong>Best for:</strong> Decision Making, Game Playing</p>
                    <p><strong>Key Features:</strong> Agent, environment, rewards</p>
                    <p><strong>Applications:</strong> Autonomous vehicles, robotics, gaming AI</p>
                    <div class="progress-bar">
                        <div class="progress-fill" style="width: 88%"></div>
                    </div>
                    <small>Popularity: 88% (Growing)</small>
                </div>
            </div>

            <button class="collapsible">🔥 Implementation Examples</button>
            <div class="collapsible-content">
                <h4>CNN for Image Classification:</h4>
                <div class="code-block">
import tensorflow as tf
from tensorflow.keras import layers

model = tf.keras.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])
                </div>

                <h4>LSTM for Sequence Prediction:</h4>
                <div class="code-block">
from tensorflow.keras.layers import LSTM, Dense

model = tf.keras.Sequential([
    LSTM(50, return_sequences=True, input_shape=(timesteps, features)),
    LSTM(50, return_sequences=False),
    Dense(25),
    Dense(1)
])
                </div>
            </div>
        </div>

        <!-- Frameworks Section -->
        <div id="frameworks" class="content-section">
            <h2 class="section-title">Python Deep Learning Frameworks</h2>
            
            <div class="framework-comparison">
                <div class="framework-card">
                    <h3>🔥 PyTorch</h3>
                    <p><strong>Developed by:</strong> Meta AI Research</p>
                    <p><strong>Best for:</strong> Research, Prototyping</p>
                    <div class="pros-cons">
                        <div class="pros">
                            <h4>✅ Pros</h4>
                            <ul>
                                <li>Dynamic computation graphs</li>
                                <li>Pythonic and intuitive</li>
                                <li>Easy debugging</li>
                                <li>Strong research community</li>
                                <li>Flexible architecture</li>
                            </ul>
                        </div>
                        <div class="cons">
                            <h4>❌ Cons</h4>
                            <ul>
                                <li>Less mature deployment tools</li>
                                <li>Smaller ecosystem</li>
                                <li>Limited mobile support</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="framework-card">
                    <h3>🔵 TensorFlow</h3>
                    <p><strong>Developed by:</strong> Google Brain</p>
                    <p><strong>Best for:</strong> Production, Deployment</p>
                    <div class="pros-cons">
                        <div class="pros">
                            <h4>✅ Pros</h4>
                            <ul>
                                <li>Production-ready</li>
                                <li>Excellent deployment tools</li>
                                <li>Mobile/edge support</li>
                                <li>Large ecosystem</li>
                                <li>Strong visualization (TensorBoard)</li>
                            </ul>
                        </div>
                        <div class="cons">
                            <h4>❌ Cons</h4>
                            <ul>
                                <li>Steeper learning curve</li>
                                <li>More verbose syntax</li>
                                <li>Less flexible for research</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>

            <div class="highlight">
                <h3>📊 2025 Framework Comparison</h3>
                <p><strong>PyTorch Market Share:</strong> 59% of research papers (growing)</p>
                <p><strong>TensorFlow Market Share:</strong> 65% of production deployments</p>
                <p><strong>Recommendation:</strong> Learn PyTorch for research/flexibility, TensorFlow for production/deployment</p>
            </div>

            <div class="cards-grid">
                <div class="card">
                    <h3>🚀 Getting Started with PyTorch</h3>
                    <div class="code-block">
import torch
import torch.nn as nn
import torch.optim as optim

# Define a simple neural network
class SimpleNN(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, output_size)
    
    def forward(self, x):
        out = self.fc1(x)
        out = self.relu(out)
        out = self.fc2(out)
        return out

# Create model and optimizer
model = SimpleNN(784, 128, 10)
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()
                    </div>
                </div>

                <div class="card">
                    <h3>🛠️ TensorFlow/Keras Example</h3>
                    <div class="code-block">
import tensorflow as tf
from tensorflow import keras

# Define model using Keras API
model = keras.Sequential([
    keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    keras.layers.Dropout(0.2),
    keras.layers.Dense(10, activation='softmax')
])

# Compile the model
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model
model.fit(x_train, y_train, epochs=5, validation_split=0.2)
                    </div>
                </div>

                <div class="card">
                    <h3>🔧 Other Popular Frameworks</h3>
                    <p><strong>Keras:</strong> High-level API (now part of TensorFlow)</p>
                    <p><strong>JAX:</strong> Google's NumPy-compatible library with JIT compilation</p>
                    <p><strong>Hugging Face:</strong> Specialized for NLP and Transformers</p>
                    <p><strong>PyTorch Lightning:</strong> High-level PyTorch wrapper</p>
                    <p><strong>FastAI:</strong> Beginner-friendly with best practices built-in</p>
                </div>
            </div>

            <button class="collapsible">🔄 Framework Migration Tips</button>
            <div class="collapsible-content">
                <h4>PyTorch to TensorFlow:</h4>
                <ul>
                    <li>Use ONNX for model conversion</li>
                    <li>Leverage TensorFlow Serving for deployment</li>
                    <li>Adapt dynamic to static graph thinking</li>
                </ul>
                <h4>TensorFlow to PyTorch:</h4>
                <ul>
                    <li>Embrace dynamic computation graphs</li>
                    <li>Use PyTorch's more Pythonic syntax</li>
                    <li>Leverage PyTorch Lightning for structure</li>
                </ul>
            </div>
        </div>

        <!-- Trends Section -->
        <div id="trends" class="content-section">
            <h2 class="section-title">🚀 2025 Deep Learning Trends</h2>
            
            <div class="cards-grid">
                <div class="card">
                    <h3>🎭 Multimodal AI</h3>
                    <p>Models that can understand and generate multiple types of data simultaneously (text, images, audio, video).</p>
                    <p><strong>Examples:</strong> GPT-4V, DALL-E 3, Sora (text-to-video)</p>
                    <p><strong>Applications:</strong> Content creation, virtual assistants, accessibility tools</p>
                </div>

                <div class="card">
                    <h3>🤖 Autonomous AI Agents</h3>
                    <p>AI systems that can perform complex tasks independently with minimal human oversight.</p>
                    <p><strong>Features:</strong> Tool usage, planning, reasoning, environment interaction</p>
                    <p><strong>Impact:</strong> Workforce productivity, automated decision-making</p>
                </div>

                <div class="card">
                    <h3>👁️ Large Vision-Language Models (VLMs)</h3>
                    <p>Advanced models combining computer vision and natural language processing capabilities.</p>
                    <p><strong>Techniques:</strong> Chain-of-thought reasoning, visual understanding</p>
                    <p><strong>Applications:</strong> Medical imaging, robotics, autonomous vehicles</p>
                </div>

                <div class="card">
                    <h3>🔐 Federated Learning</h3>
                    <p>Training models across decentralized data without sharing raw data, preserving privacy.</p>
                    <p><strong>Benefits:</strong> Data privacy, reduced bandwidth, regulatory compliance</p>
                    <p><strong>Use cases:</strong> Healthcare, finance, mobile applications</p>
                </div>

                <div class="card">
                    <h3>🧮 Geometric Deep Learning</h3>
                    <p>Processing complex geometric structures like graphs, point clouds, and manifolds.</p>
                    <p><strong>Applications:</strong> Social networks, molecular biology, 3D modeling</p>
                    <p><strong>Advantages:</strong> Better handling of non-Euclidean data</p>
                </div>

                <div class="card">
                    <h3>🤝 Reinforcement Learning from Human Feedback (RLHF)</h3>
                    <p>Training AI systems using human preferences to align with human values and intentions.</p>
                    <p><strong>Examples:</strong> ChatGPT, Claude, GPT-4</p>
                    <p><strong>Impact:</strong> More helpful, harmless, and honest AI systems</p>
                </div>

                <div class="card">
                    <h3>🔍 Explainable AI (XAI)</h3>
                    <p>Making AI decision-making processes transparent and interpretable for humans.</p>
                    <p><strong>Techniques:</strong> SHAP, LIME, attention visualization</p>
                    <p><strong>Importance:</strong> Trust, accountability, regulatory compliance</p>
                </div>

                <div class="card">
                    <h3>⚡ Small Language Models (SLMs)</h3>
                    <p>Efficient, specialized models that can run on edge devices with limited resources.</p>
                    <p><strong>Benefits:</strong> Lower cost, faster inference, privacy</p>
                    <p><strong>Examples:</strong> Phi-3, Gemma, specialized domain models</p>
                </div>
            </div>

            <div class="highlight">
                <h3>📈 Market Predictions for 2025</h3>
                <p><strong>Global ML Market:</strong> $503.40 billion by 2030 (34.8% CAGR)</p>
                <p><strong>Top Investment Areas:</strong> Multimodal AI, Autonomous Agents, Edge AI</p>
                <p><strong>Skills in Demand:</strong> MLOps, AI Ethics, Multimodal AI Development</p>
                <p><strong>Industry Leaders:</strong> Healthcare AI, Autonomous Systems, Creative AI</p>
            </div>

            <button class="collapsible">🔮 Future Predictions</button>
            <div class="collapsible-content">
                <h4>Next 2-3 Years:</h4>
                <ul>
                    <li>AI agents will become mainstream in business workflows</li>
                    <li>Multimodal models will replace specialized single-modal systems</li>
                    <li>Edge AI deployment will accelerate dramatically</li>
                    <li>AI regulations will significantly impact development practices</li>
                </ul>
                <h4>Emerging Technologies to Watch:</h4>
                <ul>
                    <li>Neuromorphic computing for AI</li>
                    <li>Quantum machine learning</li>
                    <li>Bio-inspired neural networks</li>
                    <li>Continual learning systems</li>
                </ul>
            </div>
        </div>

        <!-- Practice Section -->
        <div id="practice" class="content-section">
            <h2 class="section-title">💻 Hands-on Practice</h2>
            
            <div class="interactive-demo">
                <h3>🚀 Complete Deep Learning Projects</h3>
                <p>Follow these step-by-step implementations to build real deep learning models!</p>
                
                <div class="demo-controls">
                    <button class="demo-btn" onclick="showCode('mnist-ann')">🧠 MNIST with ANN</button>
                    <button class="demo-btn" onclick="showCode('cifar-cnn')">🖼️ CIFAR-10 with CNN</button>
                    <button class="demo-btn" onclick="showCode('sentiment-rnn')">📝 Sentiment Analysis RNN</button>
                    <button class="demo-btn" onclick="showCode('text-lstm')">🔤 Text Generation LSTM</button>
                    <button class="demo-btn" onclick="showCode('transfer-learning')">🔄 Transfer Learning</button>
                    <button class="demo-btn" onclick="showCode('simple-llm')">🤖 Simple LLM</button>
                </div>

                <div id="demo-code-display" class="code-block">
                    <p>Click the buttons above to see complete project implementations!</p>
                </div>
            </div>

            <div class="cards-grid">
                <div class="card">
                    <h3>📁 Beginner Projects (1-2 weeks)</h3>
                    <ul>
                        <li><strong>🔢 MNIST Digit Recognition:</strong> Classic ANN on handwritten digits</li>
                        <li><strong>🌸 Iris Classification:</strong> Simple neural network for flower classification</li>
                        <li><strong>🏠 House Price Prediction:</strong> Regression with neural networks</li>
                        <li><strong>👤 Binary Classification:</strong> Logistic regression with deep learning</li>
                        <li><strong>📊 Simple Data Visualization:</strong> Understanding neural network decisions</li>
                    </ul>
                    <p><strong>Skills learned:</strong> Basic PyTorch/TensorFlow, data preprocessing, model training</p>
                </div>

                <div class="card">
                    <h3>🚀 Intermediate Projects (2-4 weeks)</h3>
                    <ul>
                        <li><strong>🖼️ CIFAR-10 Image Classification:</strong> CNN for object recognition</li>
                        <li><strong>😊 Facial Expression Recognition:</strong> Multi-class image classification</li>
                        <li><strong>📰 News Article Classification:</strong> NLP with RNN/LSTM</li>
                        <li><strong>🎬 Movie Review Sentiment:</strong> Text classification project</li>
                        <li><strong>🎵 Music Genre Classification:</strong> Audio processing with CNNs</li>
                        <li><strong>🔍 Object Detection:</strong> YOLO implementation</li>
                    </ul>
                    <p><strong>Skills learned:</strong> CNNs, RNNs, data augmentation, hyperparameter tuning</p>
                </div>

                <div class="card">
                    <h3>🎯 Advanced Projects (4-8 weeks)</h3>
                    <ul>
                        <li><strong>🎨 Style Transfer:</strong> Neural artistic style transfer</li>
                        <li><strong>🗣️ Speech Recognition:</strong> Audio-to-text conversion</li>
                        <li><strong>🤖 Chatbot Development:</strong> Sequence-to-sequence models</li>
                        <li><strong>🖼️ Image Generation with GANs:</strong> Generate realistic images</li>
                        <li><strong>📈 Stock Price Prediction:</strong> Time series forecasting</li>
                        <li><strong>🔍 Recommendation System:</strong> Collaborative filtering with deep learning</li>
                        <li><strong>🏥 Medical Image Analysis:</strong> X-ray or MRI classification</li>
                    </ul>
                    <p><strong>Skills learned:</strong> GANs, attention mechanisms, advanced architectures</p>
                </div>

                <div class="card">
                    <h3>🔬 Research-Level Projects (8+ weeks)</h3>
                    <ul>
                        <li><strong>🤖 Custom LLM Implementation:</strong> Build transformer from scratch</li>
                        <li><strong>🎭 Multimodal AI:</strong> Text + image understanding</li>
                        <li><strong>🧠 Reinforcement Learning Agent:</strong> Game-playing AI</li>
                        <li><strong>🔬 Scientific Paper Analysis:</strong> NLP for research</li>
                        <li><strong>🚗 Autonomous Driving:</strong> Computer vision for vehicles</li>
                        <li><strong>💊 Drug Discovery:</strong> Molecular property prediction</li>
                        <li><strong>🌍 Climate Modeling:</strong> Environmental data analysis</li>
                    </ul>
                    <p><strong>Skills learned:</strong> Research methodologies, novel architectures, domain expertise</p>
                </div>
            </div>

            <button class="collapsible">🛠️ Complete Development Environment Setup</button>
            <div class="collapsible-content">
                <h4>🐍 Python Environment Setup:</h4>
                <div class="code-block">
# 1. Create isolated environment
conda create -n deeplearning python=3.9
conda activate deeplearning

# 2. Install deep learning frameworks
# For PyTorch (with CUDA support)
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia

# For TensorFlow (with GPU support)
pip install tensorflow[and-cuda]

# 3. Install essential libraries
pip install numpy pandas matplotlib seaborn scikit-learn
pip install jupyter notebook ipykernel
pip install wandb tensorboard  # Experiment tracking
pip install opencv-python pillow  # Image processing
pip install nltk spacy transformers  # NLP libraries
pip install plotly dash  # Interactive visualizations

# 4. Install development tools
pip install black flake8 pytest  # Code formatting and testing
pip install pre-commit  # Git hooks

# 5. Verify installation
python -c "import torch; print(f'PyTorch: {torch.__version__}')"
python -c "import tensorflow as tf; print(f'TensorFlow: {tf.__version__}')"
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
                </div>
                
                <h4>🖥️ IDE and Tools Setup:</h4>
                <div class="code-block">
# Recommended development tools:

# 1. VS Code with extensions:
# - Python
# - Jupyter
# - GitLens
# - Thunder Client (API testing)

# 2. JupyterLab for interactive development
pip install jupyterlab
jupyter lab

# 3. MLflow for experiment tracking
pip install mlflow
mlflow ui

# 4. Docker for reproducible environments
# Create Dockerfile:
FROM pytorch/pytorch:latest
WORKDIR /workspace
COPY requirements.txt .
RUN pip install -r requirements.txt
                </div>
                
                <h4>☁️ Cloud Platform Setup:</h4>
                <ul>
                    <li><strong>Google Colab:</strong> Free GPU/TPU access, no setup required</li>
                    <li><strong>Kaggle Kernels:</strong> Free GPU, integrated datasets</li>
                    <li><strong>AWS SageMaker:</strong> Professional ML platform</li>
                    <li><strong>Azure ML:</strong> Microsoft's cloud ML service</li>
                    <li><strong>Paperspace Gradient:</strong> Simple GPU cloud computing</li>
                </ul>
            </div>

            <button class="collapsible">📚 Comprehensive Learning Resources</button>
            <div class="collapsible-content">
                <h4>📖 Essential Books:</h4>
                <ul>
                    <li><strong>"Deep Learning" by Ian Goodfellow:</strong> Mathematical foundations</li>
                    <li><strong>"Hands-On Machine Learning" by Aurélien Géron:</strong> Practical approach</li>
                    <li><strong>"Deep Learning with Python" by François Chollet:</strong> TensorFlow/Keras focus</li>
                    <li><strong>"Programming PyTorch for Deep Learning" by Ian Pointer:</strong> PyTorch specialization</li>
                    <li><strong>"Natural Language Processing with Python" by Steven Bird:</strong> NLP fundamentals</li>
                </ul>
                
                <h4>🎓 Online Courses:</h4>
                <ul>
                    <li><strong>Fast.ai:</strong> Practical Deep Learning for Coders (Free)</li>
                    <li><strong>CS231n Stanford:</strong> Convolutional Neural Networks (Free)</li>
                    <li><strong>CS224n Stanford:</strong> Natural Language Processing (Free)</li>
                    <li><strong>Deep Learning Specialization (Coursera):</strong> Andrew Ng's comprehensive course</li>
                    <li><strong>MIT 6.034:</strong> Introduction to Artificial Intelligence</li>
                </ul>
                
                <h4>🛠️ Practical Platforms:</h4>
                <ul>
                    <li><strong>Kaggle:</strong> Competitions, datasets, community</li>
                    <li><strong>Papers with Code:</strong> Latest research with implementations</li>
                    <li><strong>Hugging Face:</strong> Pre-trained models and datasets</li>
                    <li><strong>GitHub:</strong> Open source projects and collaborations</li>
                    <li><strong>Reddit r/MachineLearning:</strong> Community discussions</li>
                </ul>
                
                <h4>📰 Stay Updated:</h4>
                <ul>
                    <li><strong>ArXiv:</strong> Latest research papers</li>
                    <li><strong>Distill.pub:</strong> Interpretable machine learning</li>
                    <li><strong>Towards Data Science:</strong> Medium publication</li>
                    <li><strong>AI Research newsletters:</strong> The Batch, AI Research</li>
                    <li><strong>Conferences:</strong> NeurIPS, ICML, ICLR, AAAI</li>
                </ul>
            </div>

            <button class="collapsible">🚀 Project Deployment Guide</button>
            <div class="collapsible-content">
                <h4>🌐 Web Deployment Options:</h4>
                <div class="code-block">
# 1. Streamlit for quick web apps
import streamlit as st
import torch
import torchvision.transforms as transforms
from PIL import Image

def load_model():
    model = torch.load('model.pth', map_location='cpu')
    model.eval()
    return model

def predict(image, model):
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    image_tensor = transform(image).unsqueeze(0)
    with torch.no_grad():
        output = model(image_tensor)
        prediction = torch.argmax(output, dim=1)
    
    return prediction.item()

# Streamlit app
st.title("Image Classification App")
uploaded_file = st.file_uploader("Choose an image...", type="jpg")

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.image(image, caption='Uploaded Image')
    
    model = load_model()
    prediction = predict(image, model)
    st.write(f'Prediction: {prediction}')

# Run with: streamlit run app.py
                </div>
                
                <h4>🐳 Docker Deployment:</h4>
                <div class="code-block">
# Dockerfile for model deployment
FROM python:3.9-slim

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application files
COPY . .

# Expose port
EXPOSE 8000

# Run application
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
                </div>
                
                <h4>☁️ Cloud Deployment:</h4>
                <ul>
                    <li><strong>Heroku:</strong> Simple deployment for small apps</li>
                    <li><strong>AWS Lambda:</strong> Serverless inference</li>
                    <li><strong>Google Cloud Run:</strong> Containerized applications</li>
                    <li><strong>Azure Container Instances:</strong> Quick container deployment</li>
                    <li><strong>Hugging Face Spaces:</strong> ML model hosting</li>
                </ul>
            </div>
        </div>

        <!-- Quiz Section -->
        <div id="quiz" class="content-section">
            <h2 class="section-title">🎯 Test Your Knowledge</h2>
            
            <div class="quiz-container">
                <div class="quiz-question">
                    1. What is the main difference between Machine Learning and Deep Learning?
                </div>
                <div class="quiz-options">
                    <div class="quiz-option" onclick="selectAnswer(this, false)">ML is newer than DL</div>
                    <div class="quiz-option" onclick="selectAnswer(this, true)">DL automatically learns features, ML requires manual feature engineering</div>
                    <div class="quiz-option" onclick="selectAnswer(this, false)">ML is more accurate than DL</div>
                    <div class="quiz-option" onclick="selectAnswer(this, false)">They are the same thing</div>
                </div>
            </div>

            <div class="quiz-container">
                <div class="quiz-question">
                    2. Which activation function is most commonly used in hidden layers of modern neural networks?
                </div>
                <div class="quiz-options">
                    <div class="quiz-option" onclick="selectAnswer(this, false)">Sigmoid</div>
                    <div class="quiz-option" onclick="selectAnswer(this, false)">Tanh</div>
                    <div class="quiz-option" onclick="selectAnswer(this, true)">ReLU</div>
                    <div class="quiz-option" onclick="selectAnswer(this, false)">Linear</div>
                </div>
            </div>

            <div class="quiz-container">
                <div class="quiz-question">
                    3. In CNNs, what is the primary purpose of the convolution operation?
                </div>
                <div class="quiz-options">
                    <div class="quiz-option" onclick="selectAnswer(this, true)">Detect features like edges and textures</div>
                    <div class="quiz-option" onclick="selectAnswer(this, false)">Reduce image size</div>
                    <div class="quiz-option" onclick="selectAnswer(this, false)">Add noise to images</div>
                    <div class="quiz-option" onclick="selectAnswer(this, false)">Convert color to grayscale</div>
                </div>
            </div>

            <div class="quiz-container">
                <div class="quiz-question">
                    4. What is the main advantage of PyTorch over TensorFlow for research?
                </div>
                <div class="quiz-options">
                    <div class="quiz-option" onclick="selectAnswer(this, false)">Better performance</div>
                    <div class="quiz-option" onclick="selectAnswer(this, true)">Dynamic computation graphs</div>
                    <div class="quiz-option" onclick="selectAnswer(this, false)">More deployment options</div>
                    <div class="quiz-option" onclick="selectAnswer(this, false)">Larger community</div>
                </div>
            </div>

            <div class="quiz-container">
                <div class="quiz-question">
                    5. What does pooling do in a CNN?
                </div>
                <div class="quiz-options">
                    <div class="quiz-option" onclick="selectAnswer(this, false)">Increases image resolution</div>
                    <div class="quiz-option" onclick="selectAnswer(this, true)">Reduces spatial dimensions and provides translation invariance</div>
                    <div class="quiz-option" onclick="selectAnswer(this, false)">Adds more colors to the image</div>
                    <div class="quiz-option" onclick="selectAnswer(this, false)">Converts images to text</div>
                </div>
            </div>

            <div class="quiz-container">
                <div class="quiz-question">
                    6. Which deep learning trend is most prominent in 2025?
                </div>
                <div class="quiz-options">
                    <div class="quiz-option" onclick="selectAnswer(this, false)">Single-modal models</div>
                    <div class="quiz-option" onclick="selectAnswer(this, true)">Multimodal AI</div>
                    <div class="quiz-option" onclick="selectAnswer(this, false)">Rule-based systems</div>
                    <div class="quiz-option" onclick="selectAnswer(this, false)">Traditional ML only</div>
                </div>
            </div>

            <div class="quiz-container">
                <div class="quiz-question">
                    7. When should you choose traditional ML over Deep Learning?
                </div>
                <div class="quiz-options">
                    <div class="quiz-option" onclick="selectAnswer(this, false)">When you have millions of data points</div>
                    <div class="quiz-option" onclick="selectAnswer(this, true)">When you have small datasets and need interpretability</div>
                    <div class="quiz-option" onclick="selectAnswer(this, false)">When working with images and videos</div>
                    <div class="quiz-option" onclick="selectAnswer(this, false)">Never, DL is always better</div>
                </div>
            </div>

            <div class="quiz-container">
                <div class="quiz-question">
                    8. What does RLHF stand for?
                </div>
                <div class="quiz-options">
                    <div class="quiz-option" onclick="selectAnswer(this, false)">Reinforcement Learning High Frequency</div>
                    <div class="quiz-option" onclick="selectAnswer(this, true)">Reinforcement Learning from Human Feedback</div>
                    <div class="quiz-option" onclick="selectAnswer(this, false)">Recurrent Learning Hybrid Framework</div>
                    <div class="quiz-option" onclick="selectAnswer(this, false)">Robust Learning for High Fidelity</div>
                </div>
            </div>

            <div class="quiz-container">
                <div class="quiz-question">
                    9. Which model architecture is best for sequential data?
                </div>
                <div class="quiz-options">
                    <div class="quiz-option" onclick="selectAnswer(this, false)">CNN</div>
                    <div class="quiz-option" onclick="selectAnswer(this, true)">RNN/LSTM</div>
                    <div class="quiz-option" onclick="selectAnswer(this, false)">GAN</div>
                    <div class="quiz-option" onclick="selectAnswer(this, false)">Autoencoder</div>
                </div>
            </div>

            <div class="quiz-container">
                <div class="quiz-question">
                    10. What is transfer learning in CNNs?
                </div>
                <div class="quiz-options">
                    <div class="quiz-option" onclick="selectAnswer(this, false)">Moving data between computers</div>
                    <div class="quiz-option" onclick="selectAnswer(this, true)">Using pre-trained models as starting points for new tasks</div>
                    <div class="quiz-option" onclick="selectAnswer(this, false)">Converting between different image formats</div>
                    <div class="quiz-option" onclick="selectAnswer(this, false)">Sharing models between different programming languages</div>
                </div>
            </div>
        </div>
    </div>

    <script>
        const codeExamples = {
            'data-prep': `
# Data Preparation Pipeline
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder

# Load data
data = pd.read_csv('your_dataset.csv')

# Handle missing values
data = data.dropna()

# Separate features and target
X = data.drop('target_column', axis=1)
y = data['target_column']

# Encode categorical variables
le = LabelEncoder()
for col in X.select_dtypes(include=['object']).columns:
    X[col] = le.fit_transform(X[col])

# Split the data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"Training set shape: {X_train_scaled.shape}")
print(f"Test set shape: {X_test_scaled.shape}")
            `,
            'model-build': `
# Model Building with PyTorch
import torch
import torch.nn as nn
import torch.nn.functional as F

class DeepClassifier(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes, dropout_rate=0.3):
        super(DeepClassifier, self).__init__()
        
        # Define layers
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)
        self.fc3 = nn.Linear(hidden_size // 2, hidden_size // 4)
        self.fc4 = nn.Linear(hidden_size // 4, num_classes)
        
        self.dropout = nn.Dropout(dropout_rate)
        self.batch_norm1 = nn.BatchNorm1d(hidden_size)
        self.batch_norm2 = nn.BatchNorm1d(hidden_size // 2)
        
    def forward(self, x):
        # Forward pass with residual connections
        x = F.relu(self.batch_norm1(self.fc1(x)))
        x = self.dropout(x)
        
        x = F.relu(self.batch_norm2(self.fc2(x)))
        x = self.dropout(x)
        
        x = F.relu(self.fc3(x))
        x = self.dropout(x)
        
        x = self.fc4(x)
        return x

# Initialize model
model = DeepClassifier(
    input_size=X_train.shape[1], 
    hidden_size=128, 
    num_classes=len(np.unique(y))
)

print(f"Model parameters: {sum(p.numel() for p in model.parameters())}")
            `,
            'training': `
# Training Loop
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

# Convert to tensors
X_train_tensor = torch.FloatTensor(X_train_scaled)
y_train_tensor = torch.LongTensor(y_train)
X_test_tensor = torch.FloatTensor(X_test_scaled)
y_test_tensor = torch.LongTensor(y_test)

# Create data loaders
train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# Define optimizer and loss function
optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)
criterion = nn.CrossEntropyLoss()
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5)

# Training loop
num_epochs = 100
train_losses = []
val_accuracies = []

for epoch in range(num_epochs):
    model.train()
    epoch_loss = 0
    
    for batch_X, batch_y in train_loader:
        optimizer.zero_grad()
        outputs = model(batch_X)
        loss = criterion(outputs, batch_y)
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item()
    
    # Validation
    model.eval()
    with torch.no_grad():
        val_outputs = model(X_test_tensor)
        _, predicted = torch.max(val_outputs.data, 1)
        accuracy = (predicted == y_test_tensor).float().mean()
        val_accuracies.append(accuracy.item())
    
    scheduler.step(epoch_loss)
    train_losses.append(epoch_loss / len(train_loader))
    
    if epoch % 10 == 0:
        print(f'Epoch {epoch}: Loss = {epoch_loss:.4f}, Val Acc = {accuracy:.4f}')
            `,
            'evaluation': `
# Model Evaluation and Visualization
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

# Final evaluation
model.eval()
with torch.no_grad():
    test_outputs = model(X_test_tensor)
    _, test_predicted = torch.max(test_outputs.data, 1)
    test_accuracy = (test_predicted == y_test_tensor).float().mean()

print(f"Final Test Accuracy: {test_accuracy:.4f}")

# Classification report
y_pred = test_predicted.numpy()
y_true = y_test_tensor.numpy()
print("\\nClassification Report:")
print(classification_report(y_true, y_pred))

# Confusion Matrix
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Training Loss')
plt.title('Training Loss Over Time')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(val_accuracies, label='Validation Accuracy', color='orange')
plt.title('Validation Accuracy Over Time')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# Feature importance (for interpretation)
def get_feature_importance(model, X_sample):
    model.eval()
    X_sample.requires_grad_(True)
    output = model(X_sample)
    gradients = torch.autograd.grad(output.sum(), X_sample)[0]
    importance = gradients.abs().mean(dim=0)
    return importance.detach().numpy()

# Calculate feature importance on a sample
sample_importance = get_feature_importance(model, X_test_tensor[:100])
print(f"Top 5 most important features: {np.argsort(sample_importance)[-5:]}")
            `
        };

        function showSection(sectionId) {
            // Hide all sections
            const sections = document.querySelectorAll('.content-section');
            sections.forEach(section => section.classList.remove('active'));
            
            // Remove active class from all buttons
            const buttons = document.querySelectorAll('.tab-btn');
            buttons.forEach(btn => btn.classList.remove('active'));
            
            // Show selected section
            document.getElementById(sectionId).classList.add('active');
            
            // Add active class to clicked button
            event.target.classList.add('active');
        }

        function showCode(step) {
            const codeDisplay = document.getElementById('demo-code-display');
            codeDisplay.innerHTML = `<pre><code>${codeExamples[step]}</code></pre>`;
        }

        function selectAnswer(element, isCorrect) {
            // Remove previous selections in this quiz
            const siblings = element.parentNode.querySelectorAll('.quiz-option');
            siblings.forEach(sibling => {
                sibling.classList.remove('correct', 'incorrect');
            });
            
            // Mark the selected answer
            if (isCorrect) {
                element.classList.add('correct');
            } else {
                element.classList.add('incorrect');
                // Also show the correct answer
                siblings.forEach(sibling => {
                    if (sibling.onclick.toString().includes('true')) {
                        sibling.classList.add('correct');
                    }
                });
            }
        }

        // Initialize collapsible content
        document.addEventListener('DOMContentLoaded', function() {
            const collapsibles = document.querySelectorAll('.collapsible');
            collapsibles.forEach(collapsible => {
                collapsible.addEventListener('click', function() {
                    this.classList.toggle('active');
                    const content = this.nextElementSibling;
                    content.classList.toggle('active');
                });
            });
        });

        // Add some interactive animations
        document.addEventListener('DOMContentLoaded', function() {
            // Add hover effects to cards
            const cards = document.querySelectorAll('.card, .model-card');
            cards.forEach(card => {
                card.addEventListener('mouseenter', function() {
                    this.style.transform = 'translateY(-10px) scale(1.02)';
                });
                
                card.addEventListener('mouseleave', function() {
                    this.style.transform = 'translateY(0) scale(1)';
                });
            });
        });
    </script>
</body>
</html>